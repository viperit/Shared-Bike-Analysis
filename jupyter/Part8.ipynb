{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import math\n",
    "from scipy.stats import mode\n",
    "import function\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user_cur_hour_loc_as_end_ratio,user_cur_hour_loc_as_end_cur_hour_ratio\n",
    "## user_cur_hour_loc_as_end_geofly_ratio,user_cur_hour_loc_as_end_geofly_cur_hour_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_to_end_ratio(to_end_count_path,user_count_path='./data/train_hard.csv'):\n",
    "    # 一个是终点到达次数计算的csv的路径，一个是计算用户使用了几次的path\n",
    "    # 在终点飘逸的时候，user_count_path用户使用的次数不能是飘逸的\n",
    "    \n",
    "    user_count = {}# 用户出发次数==用户行程次数\n",
    "    user_hour_count = {}# 用户每小时出发次数\n",
    "    i = 0\n",
    "    csv_reader = csv.reader(open(user_count_path, encoding='utf-8'))\n",
    "    for row in csv_reader:\n",
    "        i+=1\n",
    "        if i == 1:\n",
    "            continue\n",
    "        user = row[1]\n",
    "        hour = row[7]\n",
    "        \n",
    "        if user not in user_count:\n",
    "            user_count[user] = 1\n",
    "        else:\n",
    "            user_count[user] += 1\n",
    "        \n",
    "        if user not in user_hour_count:\n",
    "            user_hour_count[user] = {}\n",
    "            user_hour_count[user][hour] = 1\n",
    "        else:\n",
    "            if hour not in user_hour_count[user]:\n",
    "                user_hour_count[user][hour] = 1\n",
    "            else:\n",
    "                user_hour_count[user][hour] += 1\n",
    "    \n",
    "    user_cur_hour_loc_as_end = {}# 该用户该小时去该终点次数\n",
    "    \n",
    "    i = 0\n",
    "    csv_reader = csv.reader(open(to_end_count_path, encoding='utf-8'))\n",
    "    for row in csv_reader:\n",
    "        i+=1\n",
    "        if i == 1:\n",
    "            continue\n",
    "        \n",
    "        user = row[1]\n",
    "        end = row[6]\n",
    "        hour = row[7]\n",
    "        \n",
    "        if user not in user_cur_hour_loc_as_end:\n",
    "            user_cur_hour_loc_as_end[user] = {}\n",
    "            user_cur_hour_loc_as_end[user][hour] = {}\n",
    "            user_cur_hour_loc_as_end[user][hour][end] = 1\n",
    "        else:\n",
    "            if hour not in user_cur_hour_loc_as_end[user]:\n",
    "                user_cur_hour_loc_as_end[user][hour] = {}\n",
    "                user_cur_hour_loc_as_end[user][hour][end] = 1\n",
    "            else:\n",
    "                if end not in user_cur_hour_loc_as_end[user][hour]:\n",
    "                    user_cur_hour_loc_as_end[user][hour][end] = 1\n",
    "                else:\n",
    "                    user_cur_hour_loc_as_end[user][hour][end] += 1\n",
    "                    \n",
    "    user_cur_hour_loc_as_end_ratio = {}# 该用户该小时去该终点／用户总出发次数\n",
    "\n",
    "    user_cur_hour_loc_as_end_cur_hour_ratio = {}# 该用户该小时去该终点／用户该小时出发次数\n",
    "    \n",
    "    for user in user_cur_hour_loc_as_end:\n",
    "        user_cur_hour_loc_as_end_ratio[user] = {}\n",
    "        user_cur_hour_loc_as_end_cur_hour_ratio[user] = {}\n",
    "        \n",
    "        for hour in user_cur_hour_loc_as_end[user]:\n",
    "            user_cur_hour_loc_as_end_ratio[user][hour] = {}\n",
    "            user_cur_hour_loc_as_end_cur_hour_ratio[user][hour] = {}\n",
    "            \n",
    "            for end in user_cur_hour_loc_as_end[user][hour]:\n",
    "                user_cur_hour_loc_as_end_ratio[user][hour][end] = \\\n",
    "                                                user_cur_hour_loc_as_end[user][hour][end]/user_count[user]\n",
    "                user_cur_hour_loc_as_end_cur_hour_ratio[user][hour][end] = \\\n",
    "                                                user_cur_hour_loc_as_end[user][hour][end]/user_hour_count[user][hour]\n",
    "            \n",
    "            \n",
    "    return user_cur_hour_loc_as_end_ratio,user_cur_hour_loc_as_end_cur_hour_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_cur_hour_loc_as_end_ratio,user_cur_hour_loc_as_end_cur_hour_ratio = get_to_end_ratio('./data/train_hard.csv')\n",
    "\n",
    "user_cur_hour_loc_as_end_geofly_ratio,user_cur_hour_loc_as_end_geofly_cur_hour_ratio\\\n",
    "                                    = get_to_end_ratio('./data/train_end_geofly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/temp/feature_table/user_cur_hour_loc_as_end_ratio','wb+') as f:\n",
    "    pickle.dump(user_cur_hour_loc_as_end_ratio, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('./data/temp/feature_table/user_cur_hour_loc_as_end_cur_hour_ratio','wb+') as f:\n",
    "    pickle.dump(user_cur_hour_loc_as_end_cur_hour_ratio, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('./data/temp/feature_table/user_cur_hour_loc_as_end_geofly_ratio','wb+') as f:\n",
    "    pickle.dump(user_cur_hour_loc_as_end_geofly_ratio, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('./data/temp/feature_table/user_cur_hour_loc_as_end_geofly_cur_hour_ratio','wb+') as f:\n",
    "    pickle.dump(user_cur_hour_loc_as_end_geofly_cur_hour_ratio, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user_cur_hour_loc_as_start_ratio,user_cur_hour_loc_as_start_cur_hour_ratio\n",
    "## user_cur_hour_loc_as_start_geofly_ratio,user_cur_hour_loc_as_start_geofly_cur_hour_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_from_start_ratio(from_start_count_path,user_count_path='./data/train_hard.csv'):\n",
    "    # 一个是起点出发计算的csv的路径，一个是计算用户使用了几次的path\n",
    "    # 在终点飘逸的时候，user_count_path用户使用的次数不能是飘逸的\n",
    "    \n",
    "    user_count = {}# 用户出发次数==用户行程次数\n",
    "    user_hour_count = {}# 用户每小时出发次数\n",
    "    i = 0\n",
    "    csv_reader = csv.reader(open(user_count_path, encoding='utf-8'))\n",
    "    for row in csv_reader:\n",
    "        i+=1\n",
    "        if i == 1:\n",
    "            continue\n",
    "        user = row[1]\n",
    "        hour = row[7]\n",
    "        \n",
    "        if user not in user_count:\n",
    "            user_count[user] = 1\n",
    "        else:\n",
    "            user_count[user] += 1\n",
    "        \n",
    "        if user not in user_hour_count:\n",
    "            user_hour_count[user] = {}\n",
    "            user_hour_count[user][hour] = 1\n",
    "        else:\n",
    "            if hour not in user_hour_count[user]:\n",
    "                user_hour_count[user][hour] = 1\n",
    "            else:\n",
    "                user_hour_count[user][hour] += 1\n",
    "    \n",
    "    user_cur_hour_loc_as_start = {}# 该用户该小时从该起点出发次数\n",
    "    \n",
    "    i = 0\n",
    "    csv_reader = csv.reader(open(from_start_count_path, encoding='utf-8'))\n",
    "    for row in csv_reader:\n",
    "        i+=1\n",
    "        if i == 1:\n",
    "            continue\n",
    "        \n",
    "        user = row[1]\n",
    "        start = row[5]\n",
    "        hour = row[7]\n",
    "        \n",
    "        if user not in user_cur_hour_loc_as_start:\n",
    "            user_cur_hour_loc_as_start[user] = {}\n",
    "            user_cur_hour_loc_as_start[user][hour] = {}\n",
    "            user_cur_hour_loc_as_start[user][hour][start] = 1\n",
    "        else:\n",
    "            if hour not in user_cur_hour_loc_as_start[user]:\n",
    "                user_cur_hour_loc_as_start[user][hour] = {}\n",
    "                user_cur_hour_loc_as_start[user][hour][start] = 1\n",
    "            else:\n",
    "                if start not in user_cur_hour_loc_as_start[user][hour]:\n",
    "                    user_cur_hour_loc_as_start[user][hour][start] = 1\n",
    "                else:\n",
    "                    user_cur_hour_loc_as_start[user][hour][start] += 1\n",
    "                    \n",
    "    user_cur_hour_loc_as_start_ratio = {}# 该用户该小时去该终点／用户总出发次数\n",
    "\n",
    "    user_cur_hour_loc_as_start_cur_hour_ratio = {}# 该用户该小时去该终点／用户该小时出发次数\n",
    "    \n",
    "    for user in user_cur_hour_loc_as_start:\n",
    "        user_cur_hour_loc_as_start_ratio[user] = {}\n",
    "        user_cur_hour_loc_as_start_cur_hour_ratio[user] = {}\n",
    "        \n",
    "        for hour in user_cur_hour_loc_as_start[user]:\n",
    "            user_cur_hour_loc_as_start_ratio[user][hour] = {}\n",
    "            user_cur_hour_loc_as_start_cur_hour_ratio[user][hour] = {}\n",
    "            \n",
    "            for end in user_cur_hour_loc_as_start[user][hour]:\n",
    "                user_cur_hour_loc_as_start_ratio[user][hour][end] = \\\n",
    "                                                user_cur_hour_loc_as_start[user][hour][end]/user_count[user]\n",
    "                user_cur_hour_loc_as_start_cur_hour_ratio[user][hour][end] = \\\n",
    "                                                user_cur_hour_loc_as_start[user][hour][end]/user_hour_count[user][hour]\n",
    "            \n",
    "            \n",
    "    return user_cur_hour_loc_as_start_ratio,user_cur_hour_loc_as_start_cur_hour_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cur_hour_loc_as_start_ratio,user_cur_hour_loc_as_start_cur_hour_ratio = \\\n",
    "                                        get_from_start_ratio('./data/train_hard.csv')\n",
    "\n",
    "\n",
    "\n",
    "user_cur_hour_loc_as_start_geofly_ratio,user_cur_hour_loc_as_start_geofly_cur_hour_ratio\\\n",
    "                                    = get_from_start_ratio('./data/train_start_geofly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/temp/feature_table/user_cur_hour_loc_as_start_ratio','wb+') as f:\n",
    "    pickle.dump(user_cur_hour_loc_as_start_ratio, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('./data/temp/feature_table/user_cur_hour_loc_as_start_cur_hour_ratio','wb+') as f:\n",
    "    pickle.dump(user_cur_hour_loc_as_start_cur_hour_ratio, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('./data/temp/feature_table/user_cur_hour_loc_as_start_geofly_ratio','wb+') as f:\n",
    "    pickle.dump(user_cur_hour_loc_as_start_geofly_ratio, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('./data/temp/feature_table/user_cur_hour_loc_as_start_geofly_cur_hour_ratio','wb+') as f:\n",
    "    pickle.dump(user_cur_hour_loc_as_start_geofly_cur_hour_ratio, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
