{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import math\n",
    "from scipy.stats import mode\n",
    "import function\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## num_user_to_ratio,num_user_to_geofly_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_node_use_as_end_rate(path):\n",
    "\n",
    "    i = 0\n",
    "    user_count = {}\n",
    "    csv_reader = csv.reader(open('./data/temp/user_count.csv', encoding='utf-8'))\n",
    "    for row in csv_reader:\n",
    "        i+=1\n",
    "        if i == 1:\n",
    "            continue\n",
    "        user_count[row[0]] = eval(row[1])\n",
    "    \n",
    "    \n",
    "    end_node_user_dic = {}# 记录那些用户使用了终点\n",
    "    user_end_dic = {}\n",
    "    \n",
    "    i = 0\n",
    "    csv_reader = csv.reader(open(path, encoding='utf-8'))\n",
    "    for row in csv_reader:\n",
    "        i+=1\n",
    "        if i == 1:\n",
    "            continue\n",
    "        \n",
    "        user = row[1]\n",
    "        end = row[6]\n",
    "        \n",
    "        # 看每个终点用了几次\n",
    "        if user not in user_end_dic:\n",
    "            user_end_dic[user] = {}\n",
    "            user_end_dic[user][end] = 1\n",
    "        else:\n",
    "            if end not in user_end_dic[user]:\n",
    "                user_end_dic[user][end] = 1\n",
    "            else:\n",
    "                user_end_dic[user][end] += 1\n",
    "        \n",
    "        # 记录那些用户在那个终点到达过\n",
    "        if end not in end_node_user_dic:\n",
    "            end_node_user_dic[end] = set()\n",
    "            end_node_user_dic[end].add(user)\n",
    "        else:\n",
    "            end_node_user_dic[end].add(user)\n",
    "\n",
    "    \n",
    "    node_use_as_end_rate = {}\n",
    "    \n",
    "    for node in end_node_user_dic:\n",
    "        total_to = 0\n",
    "        total_used = 0\n",
    "        for user in end_node_user_dic[node]:\n",
    "            total_to+=user_end_dic[user][node]\n",
    "            total_used+=user_count[user]\n",
    "        if total_used!=0:\n",
    "            node_use_as_end_rate[node] = total_to/total_used\n",
    "        else:\n",
    "            node_use_as_end_rate[node] = 0\n",
    "            \n",
    "    return node_use_as_end_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_user_to_ratio = get_node_use_as_end_rate('./data/train_hard.csv')\n",
    "num_user_to_geofly_ratio = get_node_use_as_end_rate('./data/train_end_geofly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/temp/feature_table/num_user_to_ratio','wb+') as f:\n",
    "    pickle.dump(num_user_to_ratio, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('./data/temp/feature_table/num_user_to_geofly_ratio','wb+') as f:\n",
    "    pickle.dump(num_user_to_geofly_ratio, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## num_user_from_ratio,num_user_from_geofly_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_node_use_as_start_rate(path):\n",
    "\n",
    "    i = 0\n",
    "    user_count = {}\n",
    "    csv_reader = csv.reader(open('./data/temp/user_count.csv', encoding='utf-8'))\n",
    "    for row in csv_reader:\n",
    "        i+=1\n",
    "        if i == 1:\n",
    "            continue\n",
    "        user_count[row[0]] = eval(row[1])\n",
    "    \n",
    "    \n",
    "    start_node_user_dic = {}# 记录那些用户从点出发\n",
    "    user_start_dic = {}\n",
    "    \n",
    "    i = 0\n",
    "    csv_reader = csv.reader(open(path, encoding='utf-8'))\n",
    "    for row in csv_reader:\n",
    "        i+=1\n",
    "        if i == 1:\n",
    "            continue\n",
    "        \n",
    "        user = row[1]\n",
    "        start = row[5]\n",
    "        \n",
    "        # 看每个起点用了几次\n",
    "        if user not in user_start_dic:\n",
    "            user_start_dic[user] = {}\n",
    "            user_start_dic[user][start] = 1\n",
    "        else:\n",
    "            if start not in user_start_dic[user]:\n",
    "                user_start_dic[user][start] = 1\n",
    "            else:\n",
    "                user_start_dic[user][start] += 1\n",
    "        \n",
    "        # 记录那些用户在那个终点到达过\n",
    "        if start not in start_node_user_dic:\n",
    "            start_node_user_dic[start] = set()\n",
    "            start_node_user_dic[start].add(user)\n",
    "        else:\n",
    "            start_node_user_dic[start].add(user)\n",
    "\n",
    "    \n",
    "    node_use_as_start_rate = {}\n",
    "    \n",
    "    for node in start_node_user_dic:\n",
    "        total_from = 0\n",
    "        total_used = 0\n",
    "        for user in start_node_user_dic[node]:\n",
    "            total_from+=user_start_dic[user][node]\n",
    "            total_used+=user_count[user]\n",
    "        if total_used!=0:\n",
    "            node_use_as_start_rate[node] = total_from/total_used\n",
    "        else:\n",
    "            node_use_as_start_rate[node] = 0\n",
    "            \n",
    "    return node_use_as_start_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_user_from_ratio = get_node_use_as_start_rate('./data/train_hard.csv')\n",
    "num_user_from_geofly_ratio = get_node_use_as_start_rate('./data/train_start_geofly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/temp/feature_table/num_user_from_ratio','wb+') as f:\n",
    "    pickle.dump(num_user_from_ratio, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('./data/temp/feature_table/num_user_from_geofly_ratio','wb+') as f:\n",
    "    pickle.dump(num_user_from_geofly_ratio, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start_to_end_ratio,start_geofly_to_end_ratio\n",
    "# start_to_end_geofly_ratio,start_geofly_to_end_geofly_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_start_to_end_ratio(start_to_end_count_path,start_count_path):\n",
    "    # 一个是起点到终点次数计算的csv的路径，一个是计算start出发了几次的csv路径，\n",
    "    # 在起点飘逸的时候需要给start_count_path也是飘逸的\n",
    "    \n",
    "    node_start_count = {}# 节点出发次数\n",
    "    i = 0\n",
    "    csv_reader = csv.reader(open(start_count_path, encoding='utf-8'))\n",
    "    for row in csv_reader:\n",
    "        i+=1\n",
    "        if i == 1:\n",
    "            continue\n",
    "        start = row[5]\n",
    "        if start not in node_start_count:\n",
    "            node_start_count[start] = 1\n",
    "        else:\n",
    "            node_start_count[start] += 1\n",
    "    \n",
    "    node_start_to_end_count = {}# 起点到终点的次数\n",
    "    \n",
    "    i = 0\n",
    "    csv_reader = csv.reader(open(start_to_end_count_path, encoding='utf-8'))\n",
    "    for row in csv_reader:\n",
    "        i+=1\n",
    "        if i == 1:\n",
    "            continue\n",
    "        \n",
    "        user = row[1]\n",
    "        start = row[5]\n",
    "        end = row[6]\n",
    "        \n",
    "        if start not in node_start_to_end_count:\n",
    "            node_start_to_end_count[start] = {}\n",
    "            node_start_to_end_count[start][end] = 1\n",
    "        else:\n",
    "            if end not in node_start_to_end_count[start]:\n",
    "                node_start_to_end_count[start][end] = 1\n",
    "            else:\n",
    "                node_start_to_end_count[start][end] += 1\n",
    "        \n",
    "    node_start_to_end_count_ratio = {}\n",
    "    \n",
    "    for start in node_start_to_end_count:\n",
    "        node_start_to_end_count_ratio[start] = {}\n",
    "        for end in node_start_to_end_count[start]:\n",
    "            node_start_to_end_count_ratio[start][end] = node_start_to_end_count[start][end]/\\\n",
    "                                                        node_start_count[start]\n",
    "    \n",
    "    return node_start_to_end_count_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_start_to_end_count_ratio = get_start_to_end_ratio('./data/train_hard.csv',\\\n",
    "                                                       './data/train_hard.csv')\n",
    "node_start_geofly_to_end_count_ratio = \\\n",
    "                                    get_start_to_end_ratio('./data/train_start_geofly.csv',\\\n",
    "                                                           './data/train_start_geofly.csv')\n",
    "\n",
    "node_start_to_end_geofly_count_ratio = \\\n",
    "                                    get_start_to_end_ratio('./data/train_end_geofly.csv',\\\n",
    "                                                           './data/train_hard.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node_start_geofly_to_end_geofly_count_ratio = \\\n",
    "                                    get_start_to_end_ratio('./data/train_start_geofly_end_geofly.csv',\\\n",
    "                                                           './data/train_start_geofly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/temp/feature_table/node_start_to_end_count_ratio','wb+') as f:\n",
    "    pickle.dump(node_start_to_end_count_ratio, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('./data/temp/feature_table/node_start_geofly_to_end_count_ratio','wb+') as f:\n",
    "    pickle.dump(node_start_geofly_to_end_count_ratio, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('./data/temp/feature_table/node_start_to_end_geofly_count_ratio','wb+') as f:\n",
    "    pickle.dump(node_start_to_end_geofly_count_ratio, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('./data/temp/feature_table/node_start_geofly_to_end_geofly_count_ratio','wb+') as f:\n",
    "    pickle.dump(node_start_geofly_to_end_geofly_count_ratio, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_end_to_end_ratio(start_to_end_count_path,end_count_path):\n",
    "    # 一个是起点到终点次数计算的csv的路径，一个是计算end 到达了几次的csv路径，\n",
    "    # 在起点飘逸的时候需要给end_count_path也是飘逸的\n",
    "    \n",
    "    node_end_count = {}# 节点到达次数\n",
    "    i = 0\n",
    "    csv_reader = csv.reader(open(end_count_path, encoding='utf-8'))\n",
    "    for row in csv_reader:\n",
    "        i+=1\n",
    "        if i == 1:\n",
    "            continue\n",
    "        end = row[6]\n",
    "        if end not in node_end_count:\n",
    "            node_end_count[end] = 1\n",
    "        else:\n",
    "            node_end_count[end] += 1\n",
    "    \n",
    "    node_start_to_end_count = {}# 起点到终点的次数\n",
    "    \n",
    "    i = 0\n",
    "    csv_reader = csv.reader(open(start_to_end_count_path, encoding='utf-8'))\n",
    "    for row in csv_reader:\n",
    "        i+=1\n",
    "        if i == 1:\n",
    "            continue\n",
    "        \n",
    "        user = row[1]\n",
    "        start = row[5]\n",
    "        end = row[6]\n",
    "        \n",
    "        if start not in node_start_to_end_count:\n",
    "            node_start_to_end_count[start] = {}\n",
    "            node_start_to_end_count[start][end] = 1\n",
    "        else:\n",
    "            if end not in node_start_to_end_count[start]:\n",
    "                node_start_to_end_count[start][end] = 1\n",
    "            else:\n",
    "                node_start_to_end_count[start][end] += 1\n",
    "        \n",
    "    node_start_to_end_count_ratio = {}\n",
    "    \n",
    "    \n",
    "    for start in node_start_to_end_count:\n",
    "        node_start_to_end_count_ratio[start] = {}\n",
    "        for end in node_start_to_end_count[start]:\n",
    "            node_start_to_end_count_ratio[start][end] = node_start_to_end_count[start][end]/\\\n",
    "                                                        node_end_count[end]\n",
    "    \n",
    "    return node_start_to_end_count_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_start_to_end_count_ratio = get_end_to_end_ratio('./data/train_hard.csv',\\\n",
    "                                                       './data/train_hard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node_start_to_end_count_ratio = get_end_to_end_ratio('./data/train_start_geofly.csv',\\\n",
    "                                                       './data/train_hard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start in node_start_geofly_to_end_geofly_count_ratio:\n",
    "    t = 0\n",
    "    for end in node_start_geofly_to_end_geofly_count_ratio[start]:\n",
    "        if node_start_geofly_to_end_geofly_count_ratio[start][end] > 1:\n",
    "            print(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node_start_to_end_count_ratio = get_end_to_end_ratio('./data/train_end_geofly.csv',\\\n",
    "                                                       './data/train_end_geofly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node_start_to_end_count_ratio = get_end_to_end_ratio('./data/train_end_geofly.csv',\\\n",
    "                                                       './data/train_end_geofly.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
