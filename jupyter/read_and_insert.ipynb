{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import math\n",
    "from scipy.stats import mode\n",
    "import function\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_part1(readPath,outPath):\n",
    "    \n",
    "    print('-------------------------------insert_part1-------------------------------')\n",
    "    \n",
    "    # 出发热度\n",
    "    with open('./data/temp/feature_table/node_region_start_ratio', 'rb') as f:\n",
    "        node_region_start_ratio = pickle.load(f)\n",
    "    with open('./data/temp/feature_table/node_region_start_geofly_ratio', 'rb') as f:\n",
    "        node_region_start_geofly_ratio = pickle.load(f)\n",
    "    \n",
    "    # 到达热度\n",
    "    with open('./data/temp/feature_table/node_region_end_ratio', 'rb') as f:\n",
    "        node_region_end_ratio = pickle.load(f)\n",
    "    with open('./data/temp/feature_table/node_region_end_geofly_ratio', 'rb') as f:\n",
    "        node_region_end_geofly_ratio = pickle.load(f)\n",
    "        \n",
    "    # 总热度\n",
    "    with open('./data/temp/feature_table/node_region_overall_ratio', 'rb') as f:\n",
    "        node_region_overall_ratio = pickle.load(f)\n",
    "    with open('./data/temp/feature_table/node_region_overall_geofly_ratio', 'rb') as f:\n",
    "        node_region_overall_geofly_ratio = pickle.load(f)\n",
    "\n",
    "    with open(outPath, 'w', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "\n",
    "            i = 0\n",
    "            csv_reader = csv.reader(open(readPath, encoding='utf-8'))\n",
    "            for row in csv_reader:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "                    row.append('start_region_inheat')\n",
    "                    row.append('start_geofly_region_inheat')\n",
    "                    row.append('end_region_inheat')\n",
    "                    row.append('end_geofly_region_inheat')\n",
    "                    \n",
    "                    row.append('start_region_outheat')\n",
    "                    row.append('start_geofly_region_outheat')\n",
    "                    row.append('end_region_outheat')\n",
    "                    row.append('end_geofly_region_outheat')\n",
    "                    \n",
    "                    row.append('start_overall_heat')\n",
    "                    row.append('start_geofly_overall_heat')\n",
    "                    row.append('end_overall_heat')\n",
    "                    row.append('end_geofly_overall_heat')\n",
    "                    \n",
    "                    writer.writerow(row)\n",
    "                    continue\n",
    "\n",
    "                start = row[5]\n",
    "                end = row[6]\n",
    "                \n",
    "                # inheat 到达热度\n",
    "                row.append(node_region_end_ratio.get(start,0))\n",
    "                row.append(node_region_end_geofly_ratio.get(start,0))\n",
    "                row.append(node_region_end_ratio.get(end,0))\n",
    "                row.append(node_region_end_geofly_ratio.get(end,0))\n",
    "\n",
    "                # outheat 出发热度\n",
    "                row.append(node_region_start_ratio.get(start,0))\n",
    "                row.append(node_region_start_geofly_ratio.get(start,0))\n",
    "                row.append(node_region_start_ratio.get(end,0))\n",
    "                row.append(node_region_start_geofly_ratio.get(end,0))\n",
    "\n",
    "                # overall 总热度\n",
    "                row.append(node_region_overall_ratio.get(start,0))\n",
    "                row.append(node_region_overall_geofly_ratio.get(start,0))\n",
    "                row.append(node_region_overall_ratio.get(end,0))\n",
    "                row.append(node_region_overall_geofly_ratio.get(end,0))\n",
    "\n",
    "                # 写出\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "insert_part1(readPath='./data/train_hard.csv',outPath='./data/train_hard_p1.csv')\n",
    "insert_part1(readPath='./data/test_hard.csv',outPath='./data/test_hard_p1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_part2(readPath,outPath):\n",
    "    \n",
    "    print('-------------------------------insert_part2-------------------------------')\n",
    "    \n",
    "    # 用户去该点次数／用户出行次数\n",
    "    with open('./data/temp/feature_table/user_loc_as_end_ratio', 'rb') as f:\n",
    "        user_loc_as_end_ratio = pickle.load(f)\n",
    "    with open('./data/temp/feature_table/user_loc_as_end_geofly_ratio', 'rb') as f:\n",
    "        user_loc_as_end_geofly_ratio = pickle.load(f)\n",
    "        \n",
    "    # 用户从该点出发次数／用户出行次数\n",
    "    with open('./data/temp/feature_table/user_loc_as_start_ratio', 'rb') as f:\n",
    "        user_loc_as_start_ratio = pickle.load(f)\n",
    "    with open('./data/temp/feature_table/user_loc_as_start_geofly_ratio', 'rb') as f:\n",
    "        user_loc_as_start_geofly_ratio = pickle.load(f)\n",
    "    \n",
    "\n",
    "    with open(outPath, 'w', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "\n",
    "            i = 0\n",
    "            csv_reader = csv.reader(open(readPath, encoding='utf-8'))\n",
    "            for row in csv_reader:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "                    row.append('user_to_end_ratio')\n",
    "                    row.append('user_to_end_ratio_geofly')\n",
    "                    row.append('user_from_end_ratio')\n",
    "                    row.append('user_from_end_ratio_geofly')\n",
    "                    \n",
    "                    row.append('user_to_start_ratio')\n",
    "                    row.append('user_to_start_ratio_geofly')\n",
    "                    row.append('user_from_start_ratio')\n",
    "                    row.append('user_from_start_ratio_geofly')\n",
    "                    \n",
    "                    writer.writerow(row)\n",
    "                    continue\n",
    "                \n",
    "                user = row[1]\n",
    "                start = row[5]\n",
    "                end = row[6]\n",
    "                \n",
    "                ## 当前用户的信息\n",
    "                # 用户去该点次数／用户出行次数\n",
    "                temp_as_end = user_loc_as_end_ratio.get(user,{})\n",
    "                temp_as_end_geofly = user_loc_as_end_geofly_ratio.get(user,{})\n",
    "                \n",
    "                # 用户从该点出发次数／用户出行次数\n",
    "                temp_as_start = user_loc_as_start_ratio.get(user,{})\n",
    "                temp_as_start_geofly = user_loc_as_start_geofly_ratio.get(user,{})\n",
    "                \n",
    "                \n",
    "                row.append(temp_as_end.get(end,0))\n",
    "                row.append(temp_as_end_geofly.get(end,0))\n",
    "                row.append(temp_as_start.get(end,0))\n",
    "                row.append(temp_as_start_geofly.get(end,0))\n",
    "\n",
    "                \n",
    "                row.append(temp_as_end.get(start,0))\n",
    "                row.append(temp_as_end_geofly.get(start,0))\n",
    "                row.append(temp_as_start.get(start,0))\n",
    "                row.append(temp_as_start_geofly.get(start,0))\n",
    "\n",
    "                # 写出\n",
    "                writer.writerow(row)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "insert_part2(readPath='./data/train_hard_p1.csv',outPath='./data/train_hard_p2.csv')\n",
    "insert_part2(readPath='./data/test_hard_p1.csv',outPath='./data/test_hard_p2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_part3(readPath,outPath):\n",
    "    \n",
    "    print('-------------------------------insert_part3-------------------------------')\n",
    "    \n",
    "    # 用户从此起点到此终点的次数占用户历史次数的比重\n",
    "    with open('./data/temp/feature_table/user_start_to_end_ratio', 'rb') as f:\n",
    "        user_start_to_end_ratio = pickle.load(f)\n",
    "    with open('./data/temp/feature_table/user_start_geofly_to_end_ratio', 'rb') as f:\n",
    "        user_start_geofly_to_end_ratio = pickle.load(f)\n",
    "        \n",
    "    with open('./data/temp/feature_table/user_start_to_end_geofly_ratio', 'rb') as f:\n",
    "        user_start_to_end_geofly_ratio = pickle.load(f)\n",
    "    with open('./data/temp/feature_table/user_start_geofly_to_end_geofly_ratio', 'rb') as f:\n",
    "        user_start_geofly_to_end_geofly_ratio = pickle.load(f)\n",
    "    \n",
    "\n",
    "    with open(outPath, 'w', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "\n",
    "            i = 0\n",
    "            csv_reader = csv.reader(open(readPath, encoding='utf-8'))\n",
    "            for row in csv_reader:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "                    \n",
    "                    row.append('user_start_to_end_ratio')\n",
    "                    row.append('user_start_geofly_to_end_ratio')\n",
    "                    row.append('user_start_to_end_geofly_ratio')\n",
    "                    row.append('user_start_geofly_to_end_geofly_ratio')\n",
    "                    \n",
    "                    row.append('user_end_to_start_ratio')\n",
    "                    row.append('user_end_to_start_geofly_ratio')\n",
    "                    row.append('user_end_geofly_to_start_ratio')\n",
    "                    row.append('user_end_geofly_to_start_geofly_ratio')\n",
    "                    \n",
    "                    writer.writerow(row)\n",
    "                    continue\n",
    "                \n",
    "                user = row[1]\n",
    "                start = row[5]\n",
    "                end = row[6]\n",
    "                \n",
    "                ## 当前用户的信息\n",
    "                # 用户从此起点到此终点的次数占用户历史次数的比重\n",
    "                temp_start_to_end = user_start_to_end_ratio.get(user,{})\n",
    "                temp_start_geofly_to_end_ratio = user_start_geofly_to_end_ratio.get(user,{})\n",
    "                \n",
    "                temp_start_to_end_geofly_ratio = user_start_to_end_geofly_ratio.get(user,{})\n",
    "                temp_start_geofly_to_end_geofly = user_start_geofly_to_end_geofly_ratio.get(user,{})\n",
    "                \n",
    "                # 用户从此起点到此终点的次数占用户历史次数的比重\n",
    "                if start not in temp_start_to_end or end not in temp_start_to_end[start]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(temp_start_to_end[start][end])\n",
    "                    \n",
    "                # 用户从此起点（扩大9倍）到此终点的次数占用户历史次数的比重\n",
    "                if start not in temp_start_geofly_to_end_ratio or end not in temp_start_geofly_to_end_ratio[start]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(temp_start_geofly_to_end_ratio[start][end])\n",
    "                    \n",
    "                # 用户从此起点到此终点（扩大9倍）的次数占用户历史次数的比重\n",
    "                if start not in temp_start_to_end_geofly_ratio or end not in temp_start_to_end_geofly_ratio[start]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(temp_start_to_end_geofly_ratio[start][end])\n",
    "                    \n",
    "                # 用户从此起点（扩大9倍）到此终点（扩大9倍）的次数占用户历史次数的比重\n",
    "                if start not in temp_start_geofly_to_end_geofly or end not in temp_start_geofly_to_end_geofly[start]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(temp_start_geofly_to_end_geofly[start][end])\n",
    "                    \n",
    "                \n",
    "                \n",
    "                # 用户从此终点到此起点的次数占用户历史次数的比重\n",
    "                if end not in temp_start_to_end or start not in temp_start_to_end[end]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(temp_start_to_end[end][start])\n",
    "                    \n",
    "                # 用户从此终点到此起点（扩大9倍）的次数占用户历史次数的比重\n",
    "                if end not in temp_start_geofly_to_end_ratio or start not in temp_start_geofly_to_end_ratio[end]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(temp_start_geofly_to_end_ratio[end][start])\n",
    "                    \n",
    "                # 用户从此终点（扩大9倍）到此起点的次数占用户历史次数的比重\n",
    "                if end not in temp_start_to_end_geofly_ratio or start not in temp_start_to_end_geofly_ratio[end]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(temp_start_to_end_geofly_ratio[end][start])\n",
    "                    \n",
    "                # 用户从此终点（扩大9倍）到此起点（扩大9倍）的次数占用户历史次数的比重\n",
    "                if end not in temp_start_geofly_to_end_geofly or start not in temp_start_geofly_to_end_geofly[end]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(temp_start_geofly_to_end_geofly[end][start])\n",
    "\n",
    "                # 写出\n",
    "                writer.writerow(row)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "insert_part3(readPath='./data/train_hard_p2.csv',outPath='./data/train_hard_p3.csv')\n",
    "insert_part3(readPath='./data/test_hard_p2.csv',outPath='./data/test_hard_p3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_part4(readPath,outPath):\n",
    "    \n",
    "    print('-------------------------------insert_part4-------------------------------')\n",
    "    \n",
    "    # 当前小时进出总热度\n",
    "    with open('./data/temp/feature_table/node_region_hour_end_geofly_ratio', 'rb') as f:\n",
    "        node_region_hour_end_geofly_ratio = pickle.load(f)\n",
    "    with open('./data/temp/feature_table/node_region_hour_end_ratio', 'rb') as f:\n",
    "        node_region_hour_end_ratio = pickle.load(f)\n",
    "        \n",
    "    with open('./data/temp/feature_table/node_region_hour_overall_geofly_ratio', 'rb') as f:\n",
    "        node_region_hour_overall_geofly_ratio = pickle.load(f)\n",
    "    with open('./data/temp/feature_table/node_region_hour_overall_ratio', 'rb') as f:\n",
    "        node_region_hour_overall_ratio = pickle.load(f)\n",
    "        \n",
    "    with open('./data/temp/feature_table/node_region_hour_start_geofly_ratio', 'rb') as f:\n",
    "        node_region_hour_start_geofly_ratio = pickle.load(f)\n",
    "    with open('./data/temp/feature_table/node_region_hour_start_ratio', 'rb') as f:\n",
    "        node_region_hour_start_ratio = pickle.load(f)\n",
    "    \n",
    "\n",
    "    with open(outPath, 'w', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "\n",
    "            i = 0\n",
    "            csv_reader = csv.reader(open(readPath, encoding='utf-8'))\n",
    "            for row in csv_reader:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "                    \n",
    "                    row.append('start_cur_hour_region_inheat')\n",
    "                    row.append('start_cur_hour_geofly_region_inheat')\n",
    "                    row.append('end_cur_hour_region_inheat')\n",
    "                    row.append('end_cur_hour_geofly_region_inheat')\n",
    "                    \n",
    "                    row.append('start_cur_hour_region_outheat')\n",
    "                    row.append('start_cur_hour_geofly_region_outheat')\n",
    "                    row.append('end_cur_hour_region_outheat')\n",
    "                    row.append('end_cur_hour_geofly_region_outheat')\n",
    "                    \n",
    "                    row.append('start_cur_hour_overall_heat')\n",
    "                    row.append('start_cur_hour_geofly_overall_heat')\n",
    "                    row.append('end_cur_hour_overall_heat')\n",
    "                    row.append('end_cur_hour_geofly_overall_heat')\n",
    "                    \n",
    "                    writer.writerow(row)\n",
    "                    continue\n",
    "                \n",
    "                user = row[1]\n",
    "                start = row[5]\n",
    "                end = row[6]\n",
    "                hour = row[7]\n",
    "                \n",
    "                # 作为终点的inheat\n",
    "                temp_hour_end_geofly = node_region_hour_end_geofly_ratio.get(hour,{})\n",
    "                temp_hour_end = node_region_hour_end_ratio.get(hour,{})\n",
    "                \n",
    "                # 作为起点的outheat\n",
    "                temp_hour_start_geofly = node_region_hour_start_geofly_ratio.get(hour,{})\n",
    "                temp_hour_start = node_region_hour_start_ratio.get(hour,{})\n",
    "                \n",
    "                # 总heat\n",
    "                temp_hour_overall_geofly = node_region_hour_overall_geofly_ratio.get(hour,{})\n",
    "                temp_hour_overall = node_region_hour_overall_ratio.get(hour,{})\n",
    "                \n",
    "                \n",
    "                # inheat 到达热度\n",
    "                row.append(temp_hour_end.get(start,0))\n",
    "                row.append(temp_hour_end_geofly.get(start,0))\n",
    "                row.append(temp_hour_end.get(end,0))\n",
    "                row.append(temp_hour_end_geofly.get(end,0))\n",
    "\n",
    "                # outheat 出发热度\n",
    "                row.append(temp_hour_start.get(start,0))\n",
    "                row.append(temp_hour_start_geofly.get(start,0))\n",
    "                row.append(temp_hour_start.get(end,0))\n",
    "                row.append(temp_hour_start_geofly.get(end,0))\n",
    "\n",
    "                # overall 总热度\n",
    "                row.append(temp_hour_overall.get(start,0))\n",
    "                row.append(temp_hour_overall_geofly.get(start,0))\n",
    "                row.append(temp_hour_overall.get(end,0))\n",
    "                row.append(temp_hour_overall_geofly.get(end,0))\n",
    "\n",
    "                # 写出\n",
    "                writer.writerow(row)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "insert_part4(readPath='./data/train_hard_p3.csv',outPath='./data/train_hard_p4.csv')\n",
    "insert_part4(readPath='./data/test_hard_p3.csv',outPath='./data/test_hard_p4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 去过该点的用户去该终点的总数/去过该点的用户使用的总次数\n",
    "with open('./data/temp/feature_table/num_user_to_ratio', 'rb') as f:\n",
    "    num_user_to_ratio = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_part5(readPath,outPath):\n",
    "    \n",
    "    print('-------------------------------insert_part5-------------------------------')\n",
    "    \n",
    "    # 去过该点的用户去该终点的总数/去过该点的用户使用的总次数\n",
    "    with open('./data/temp/feature_table/num_user_to_ratio', 'rb') as f:\n",
    "        num_user_to_ratio = pickle.load(f)\n",
    "        \n",
    "    # 从该点出发的用户去该终点的总数/从该点出发的用户使用的总次数\n",
    "    with open('./data/temp/feature_table/num_user_from_ratio', 'rb') as f:\n",
    "        num_user_from_ratio = pickle.load(f)\n",
    "        \n",
    "    with open('./data/temp/feature_table/num_user_to_geofly_ratio', 'rb') as f:\n",
    "        num_user_to_geofly_ratio = pickle.load(f)\n",
    "    with open('./data/temp/feature_table/num_user_from_geofly_ratio', 'rb') as f:\n",
    "        num_user_from_geofly_ratio = pickle.load(f)\n",
    "    \n",
    "    with open(outPath, 'w', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            \n",
    "            i = 0\n",
    "            csv_reader = csv.reader(open(readPath, encoding='utf-8'))\n",
    "            for row in csv_reader:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "                    \n",
    "                    row.append('num_user_to_end_ratio')\n",
    "                    row.append('num_user_to_end_ratio_geofly')\n",
    "                    row.append('num_user_from_end_ratio')\n",
    "                    row.append('num_user_from_end_ratio_geofly')\n",
    "                    \n",
    "                    row.append('num_user_to_start_ratio')\n",
    "                    row.append('num_user_to_start_ratio_geofly')\n",
    "                    row.append('num_user_from_start_ratio')\n",
    "                    row.append('num_user_from_start_ratio_geofly')\n",
    "                 \n",
    "                    writer.writerow(row)\n",
    "                    continue\n",
    "                \n",
    "                user = row[1]\n",
    "                start = row[5]\n",
    "                end = row[6]\n",
    "                 \n",
    "                # 终点\n",
    "                row.append(num_user_to_ratio.get(end,0))\n",
    "                row.append(num_user_to_geofly_ratio.get(end,0))\n",
    "                row.append(num_user_from_ratio.get(end,0))\n",
    "                row.append(num_user_from_geofly_ratio.get(end,0))\n",
    "\n",
    "                # 起点\n",
    "                row.append(num_user_to_ratio.get(start,0))\n",
    "                row.append(num_user_to_geofly_ratio.get(start,0))\n",
    "                row.append(num_user_from_ratio.get(start,0))\n",
    "                row.append(num_user_from_geofly_ratio.get(start,0))\n",
    "                \n",
    "                # 写出\n",
    "                writer.writerow(row)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "insert_part5(readPath='./data/train_hard_p4.csv',outPath='./data/train_hard_p5.csv')\n",
    "insert_part5(readPath='./data/test_hard_p4.csv',outPath='./data/test_hard_p5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_part6(readPath,outPath):\n",
    "    \n",
    "    print('-------------------------------insert_part6-------------------------------')\n",
    "    \n",
    "    # 点1到点2行程次数/点1总出发次数\n",
    "    with open('./data/temp/feature_table/start_to_end_start_out_ratio', 'rb') as f:\n",
    "        start_to_end_start_out_ratio = pickle.load(f)\n",
    "            \n",
    "    # 点1(geofly)到点2行程次数/点1(geofly)总出发次数\n",
    "    with open('./data/temp/feature_table/start_geofly_to_end_start_geofly_out_ratio', 'rb') as f:\n",
    "        start_geofly_to_end_start_geofly_out_ratio = pickle.load(f)\n",
    "        \n",
    "    # 点1到点2(geofly)行程次数/点1总出发次数\n",
    "    with open('./data/temp/feature_table/start_to_end_geofly_start_out_ratio', 'rb') as f:\n",
    "        start_to_end_geofly_start_out_ratio = pickle.load(f)\n",
    "        \n",
    "    # 点1(geofly)到点2(geofly)行程次数/点1(geofly)总出发次数\n",
    "    with open('./data/temp/feature_table/start_geofly_to_end_geofly_start_geofly_out_ratio', 'rb') as f:\n",
    "        start_geofly_to_end_geofly_start_geofly_out_ratio = pickle.load(f)\n",
    "        \n",
    "    with open(outPath, 'w', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            \n",
    "            i = 0\n",
    "            csv_reader = csv.reader(open(readPath, encoding='utf-8'))\n",
    "            for row in csv_reader:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "                    \n",
    "                    row.append('start_to_end_start_out_ratio')\n",
    "                    row.append('start_geofly_to_end_start_geofly_out_ratio')\n",
    "                    row.append('start_to_end_geofly_start_out_ratio')\n",
    "                    row.append('start_geofly_to_end_geofly_start_geofly_out_ratio')\n",
    "                    \n",
    "                    row.append('end_to_start_end_out_ratio')\n",
    "                    row.append('end_geofly_to_start_end_geofly_out_ratio')\n",
    "                    row.append('end_to_start_geofly_end_out_ratio')\n",
    "                    row.append('end_geofly_to_start_geofly_end_geofly_out_ratio')\n",
    "                 \n",
    "                    writer.writerow(row)\n",
    "                    continue\n",
    "\n",
    "                    \n",
    "                start = row[5]\n",
    "                end = row[6]\n",
    "                \n",
    "                \n",
    "                # start to end\n",
    "                if start not in start_to_end_start_out_ratio or end not in start_to_end_start_out_ratio[start]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(start_to_end_start_out_ratio[start][end])\n",
    "                    \n",
    "                if start not in start_geofly_to_end_start_geofly_out_ratio or end not in start_geofly_to_end_start_geofly_out_ratio[start]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(start_geofly_to_end_start_geofly_out_ratio[start][end])\n",
    "                    \n",
    "                if start not in start_to_end_geofly_start_out_ratio or end not in start_to_end_geofly_start_out_ratio[start]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(start_to_end_geofly_start_out_ratio[start][end])\n",
    "                    \n",
    "                if start not in start_geofly_to_end_geofly_start_geofly_out_ratio or end not in start_geofly_to_end_geofly_start_geofly_out_ratio[start]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(start_geofly_to_end_geofly_start_geofly_out_ratio[start][end])\n",
    "                \n",
    "               # end to start\n",
    "                if end not in start_to_end_start_out_ratio or start not in start_to_end_start_out_ratio[end]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(start_to_end_start_out_ratio[end][start])\n",
    "                    \n",
    "                if end not in start_geofly_to_end_start_geofly_out_ratio or start not in start_geofly_to_end_start_geofly_out_ratio[end]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(start_geofly_to_end_start_geofly_out_ratio[end][start])\n",
    "                    \n",
    "                if end not in start_to_end_geofly_start_out_ratio or start not in start_to_end_geofly_start_out_ratio[end]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(start_to_end_geofly_start_out_ratio[end][start])\n",
    "                    \n",
    "                if end not in start_geofly_to_end_geofly_start_geofly_out_ratio or start not in start_geofly_to_end_geofly_start_geofly_out_ratio[end]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(start_geofly_to_end_geofly_start_geofly_out_ratio[end][start])\n",
    "                \n",
    "                # 写出\n",
    "                writer.writerow(row)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_part6(readPath='./data/train_hard_p5.csv',outPath='./data/train_hard_p6.csv')\n",
    "insert_part6(readPath='./data/test_hard_p5.csv',outPath='./data/test_hard_p6.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 点1(geofly)到点2(geofly)行程次数/点2(geofly)总到达次数\n",
    "with open('./data/temp/feature_table/start_geofly_to_end_geofly_end_in_ratio', 'rb') as f:\n",
    "    start_geofly_to_end_geofly_end_in_ratio = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start='wx4e1zx'\n",
    "end='wx4e1zv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20689655172413793"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_geofly_to_end_geofly_end_in_ratio[start][end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250004    0.206897\n",
       "304758    0.206897\n",
       "Name: start_geofly_to_end_geofly_end_geofly_in_ratio, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[(test.geohashed_start_loc==start)&(test.geohashed_end_loc==end)].start_geofly_to_end_geofly_end_geofly_in_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_part7(readPath,outPath):\n",
    "    \n",
    "    print('-------------------------------insert_part7-------------------------------')\n",
    "    \n",
    "    # 点1到点2行程次数/点2总到达次数\n",
    "    with open('./data/temp/feature_table/start_to_end_end_in_ratio', 'rb') as f:\n",
    "        start_to_end_end_in_ratio = pickle.load(f)\n",
    "        \n",
    "    # 点1(geofly)到点2行程次数/点2总到达次数\n",
    "    with open('./data/temp/feature_table/start_geofly_to_end_end_in_ratio', 'rb') as f:\n",
    "        start_geofly_to_end_end_in_ratio = pickle.load(f)\n",
    "        \n",
    "    # 点1到点2(geofly)行程次数/点2(geofly)总到达次数\n",
    "    with open('./data/temp/feature_table/start_to_end_geofly_end_geofly_in_ratio', 'rb') as f:\n",
    "        start_to_end_geofly_end_geofly_in_ratio = pickle.load(f)\n",
    "        \n",
    "    # 点1(geofly)到点2(geofly)行程次数/点2(geofly)总到达次数\n",
    "    with open('./data/temp/feature_table/start_geofly_to_end_geofly_end_in_ratio', 'rb') as f:\n",
    "        start_geofly_to_end_geofly_end_in_ratio = pickle.load(f)\n",
    "        \n",
    "    with open(outPath, 'w', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            \n",
    "            i = 0\n",
    "            csv_reader = csv.reader(open(readPath, encoding='utf-8'))\n",
    "            for row in csv_reader:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "                    \n",
    "                    row.append('start_to_end_end_in_ratio')\n",
    "                    row.append('start_geofly_to_end_end_in_ratio')\n",
    "                    row.append('start_to_end_geofly_end_geofly_in_ratio')\n",
    "                    row.append('start_geofly_to_end_geofly_end_geofly_in_ratio')\n",
    "                    \n",
    "                    row.append('end_to_start_start_in_ratio')\n",
    "                    row.append('end_geofly_to_start_start_in_ratio')\n",
    "                    row.append('end_to_start_geofly_start_geofly_in_ratio')\n",
    "                    row.append('end_geofly_to_start_geofly_start_geofly_in_ratio')\n",
    "                 \n",
    "                    writer.writerow(row)\n",
    "                    continue\n",
    " \n",
    "                start = row[5]\n",
    "                end = row[6]                \n",
    "                \n",
    "                # start to end\n",
    "                if start not in start_to_end_end_in_ratio or end not in start_to_end_end_in_ratio[start]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(start_to_end_end_in_ratio[start][end])\n",
    "                    \n",
    "                if start not in start_geofly_to_end_end_in_ratio or end not in start_geofly_to_end_end_in_ratio[start]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(start_geofly_to_end_end_in_ratio[start][end])\n",
    "                    \n",
    "                if start not in start_to_end_geofly_end_geofly_in_ratio or end not in start_to_end_geofly_end_geofly_in_ratio[start]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(start_to_end_geofly_end_geofly_in_ratio[start][end])\n",
    "                    \n",
    "                if start not in start_geofly_to_end_geofly_end_in_ratio or end not in start_geofly_to_end_geofly_end_in_ratio[start]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(start_geofly_to_end_geofly_end_in_ratio[start][end])\n",
    "                \n",
    "               # end to start\n",
    "                if end not in start_to_end_end_in_ratio or start not in start_to_end_end_in_ratio[end]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(start_to_end_end_in_ratio[end][start])\n",
    "                    \n",
    "                if end not in start_geofly_to_end_end_in_ratio or start not in start_geofly_to_end_end_in_ratio[end]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(start_geofly_to_end_end_in_ratio[end][start])\n",
    "                    \n",
    "                if end not in start_to_end_geofly_end_geofly_in_ratio or start not in start_to_end_geofly_end_geofly_in_ratio[end]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(start_to_end_geofly_end_geofly_in_ratio[end][start])\n",
    "                    \n",
    "                if end not in start_geofly_to_end_geofly_end_in_ratio or start not in start_geofly_to_end_geofly_end_in_ratio[end]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(start_geofly_to_end_geofly_end_in_ratio[end][start])\n",
    "                \n",
    "                # 写出\n",
    "                writer.writerow(row)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_part7(readPath='./data/train_hard_p6.csv',outPath='./data/train_hard_p7.csv')\n",
    "insert_part7(readPath='./data/test_hard_p6.csv',outPath='./data/test_hard_p7.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## part8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_part8(readPath,outPath):\n",
    "    \n",
    "    print('-------------------------------insert_part8-------------------------------')\n",
    "    \n",
    "    # 该用户该小时去该点／用户总出发次数\n",
    "    with open('./data/temp/feature_table/user_cur_hour_loc_as_end_ratio', 'rb') as f:\n",
    "        user_cur_hour_loc_as_end_ratio = pickle.load(f)\n",
    "        \n",
    "    # 该用户该小时去该点／用户该小时出发次数\n",
    "    with open('./data/temp/feature_table/user_cur_hour_loc_as_end_cur_hour_ratio', 'rb') as f:\n",
    "        user_cur_hour_loc_as_end_cur_hour_ratio = pickle.load(f)\n",
    "        \n",
    "    with open('./data/temp/feature_table/user_cur_hour_loc_as_end_geofly_ratio', 'rb') as f:\n",
    "        user_cur_hour_loc_as_end_geofly_ratio = pickle.load(f)\n",
    "    with open('./data/temp/feature_table/user_cur_hour_loc_as_end_geofly_cur_hour_ratio', 'rb') as f:\n",
    "        user_cur_hour_loc_as_end_geofly_cur_hour_ratio = pickle.load(f)\n",
    "        \n",
    "        \n",
    "    # 该用户该小时从该点出发／用户总出发次数\n",
    "    with open('./data/temp/feature_table/user_cur_hour_loc_as_start_ratio', 'rb') as f:\n",
    "        user_cur_hour_loc_as_start_ratio = pickle.load(f)\n",
    "        \n",
    "    # 该用户该小时从该点出发／用户该小时出发次数\n",
    "    with open('./data/temp/feature_table/user_cur_hour_loc_as_start_cur_hour_ratio', 'rb') as f:\n",
    "        user_cur_hour_loc_as_start_cur_hour_ratio = pickle.load(f)\n",
    "        \n",
    "    with open('./data/temp/feature_table/user_cur_hour_loc_as_start_geofly_ratio', 'rb') as f:\n",
    "        user_cur_hour_loc_as_start_geofly_ratio = pickle.load(f)\n",
    "    with open('./data/temp/feature_table/user_cur_hour_loc_as_start_geofly_cur_hour_ratio', 'rb') as f:\n",
    "        user_cur_hour_loc_as_start_geofly_cur_hour_ratio = pickle.load(f)\n",
    "        \n",
    "        \n",
    "    with open(outPath, 'w', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            \n",
    "            i = 0\n",
    "            csv_reader = csv.reader(open(readPath, encoding='utf-8'))\n",
    "            for row in csv_reader:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "                    \n",
    "                    row.append('user_cur_hour_to_end_ratio')\n",
    "                    row.append('user_cur_hour_to_end_cur_hour_ratio')\n",
    "                    row.append('user_cur_hour_to_end_geofly_ratio')\n",
    "                    row.append('user_cur_hour_to_end_geofly_cur_hour_ratio')\n",
    "                    \n",
    "                    row.append('user_cur_hour_from_end_ratio')\n",
    "                    row.append('user_cur_hour_from_end_cur_hour_ratio')\n",
    "                    row.append('user_cur_hour_from_end_geofly_ratio')\n",
    "                    row.append('user_cur_hour_from_end_geofly_cur_hour_ratio')\n",
    "                    \n",
    "                    row.append('user_cur_hour_to_start_ratio')\n",
    "                    row.append('user_cur_hour_to_start_cur_hour_ratio')\n",
    "                    row.append('user_cur_hour_to_start_geofly_ratio')\n",
    "                    row.append('user_cur_hour_to_start_geofly_cur_hour_ratio')\n",
    "                    \n",
    "                    row.append('user_cur_hour_from_start_ratio')\n",
    "                    row.append('user_cur_hour_from_start_cur_hour_ratio')\n",
    "                    row.append('user_cur_hour_from_start_geofly_ratio')\n",
    "                    row.append('user_cur_hour_from_start_geofly_cur_hour_ratio')\n",
    "                 \n",
    "                    writer.writerow(row)\n",
    "                    continue\n",
    " \n",
    "                user = row[1]\n",
    "                start = row[5]\n",
    "                end = row[6]    \n",
    "                hour = row[7]\n",
    "                \n",
    "                temp_loc_as_end_ratio = user_cur_hour_loc_as_end_ratio.get(user,{}).get(hour,{})\n",
    "                temp_loc_as_end_cur_hour_ratio = user_cur_hour_loc_as_end_cur_hour_ratio.get(user,{}).get(hour,{})\n",
    "                \n",
    "                temp_loc_as_end_geofly_ratio = user_cur_hour_loc_as_end_geofly_ratio.get(user,{}).get(hour,{})\n",
    "                temp_loc_as_end_geofly_cur_hour_ratio = user_cur_hour_loc_as_end_geofly_cur_hour_ratio.get(user,{}).get(hour,{})\n",
    "                \n",
    "                temp_loc_as_start_ratio = user_cur_hour_loc_as_start_ratio.get(user,{}).get(hour,{})\n",
    "                temp_loc_as_start_cur_hour_ratio = user_cur_hour_loc_as_start_cur_hour_ratio.get(user,{}).get(hour,{})\n",
    "                \n",
    "                temp_loc_as_start_geofly_ratio = user_cur_hour_loc_as_start_geofly_ratio.get(user,{}).get(hour,{})\n",
    "                temp_loc_as_start_geofly_cur_hour_ratio = user_cur_hour_loc_as_start_geofly_cur_hour_ratio.get(user,{}).get(hour,{})\n",
    "                \n",
    "                \n",
    "                # 该用户该小时去该终点／用户总出发次数\n",
    "                row.append(temp_loc_as_end_ratio.get(end,0))\n",
    "                # 该用户该小时去该终点／用户该小时出发次数\n",
    "                row.append(temp_loc_as_end_cur_hour_ratio.get(end,0))\n",
    "                # 该用户该小时去该终点（geofly）／用户总出发次数\n",
    "                row.append(temp_loc_as_end_geofly_ratio.get(end,0))\n",
    "                # 该用户该小时去该终点（geofly）／用户该小时出发次数\n",
    "                row.append(temp_loc_as_end_geofly_cur_hour_ratio.get(end,0))\n",
    "                \n",
    "                # 该用户该小时从该终点出发／用户总出发次数\n",
    "                row.append(temp_loc_as_start_ratio.get(end,0))\n",
    "                # 该用户该小时从该终点出发／用户该小时出发次数\n",
    "                row.append(temp_loc_as_start_cur_hour_ratio.get(end,0))\n",
    "                # 该用户该小时从该终点（geofly）出发／用户总出发次数\n",
    "                row.append(temp_loc_as_start_geofly_ratio.get(end,0))\n",
    "                # 该用户该小时从该终点（geofly）出发／用户该小时出发次数\n",
    "                row.append(temp_loc_as_start_geofly_cur_hour_ratio.get(end,0))\n",
    "                \n",
    "                \n",
    "                # 该用户该小时去该起点／用户总出发次数\n",
    "                row.append(temp_loc_as_end_ratio.get(start,0))\n",
    "                # 该用户该小时去该起点／用户该小时出发次数\n",
    "                row.append(temp_loc_as_end_cur_hour_ratio.get(start,0))\n",
    "                # 该用户该小时去该起点（geofly）／用户总出发次数\n",
    "                row.append(temp_loc_as_end_geofly_ratio.get(start,0))\n",
    "                # 该用户该小时去该起点（geofly）／用户该小时出发次数\n",
    "                row.append(temp_loc_as_end_geofly_cur_hour_ratio.get(start,0))\n",
    "\n",
    "                # 该用户该小时从起点出发／用户总出发次数\n",
    "                row.append(temp_loc_as_start_ratio.get(start,0))\n",
    "                # 该用户该小时从起点出发／用户该小时出发次数\n",
    "                row.append(temp_loc_as_start_cur_hour_ratio.get(start,0))\n",
    "                # 该用户该小时从起点（geofly）出发／用户总出发次数\n",
    "                row.append(temp_loc_as_start_geofly_ratio.get(start,0))\n",
    "                # 该用户该小时从起点（geofly）出发／用户该小时出发次数\n",
    "                row.append(temp_loc_as_start_geofly_cur_hour_ratio.get(start,0))\n",
    "                \n",
    "                # 写出\n",
    "                writer.writerow(row)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_part8(readPath='./data/train_hard_p7.csv',outPath='./data/train_hard_p8.csv')\n",
    "insert_part8(readPath='./data/test_hard_p7.csv',outPath='./data/test_hard_p8.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_part9A(readPath,outPath):\n",
    "    \n",
    "    print('-------------------------------insert_part9A-------------------------------')\n",
    "    \n",
    "    with open('./data/temp/feature_table/user_cur_hour_start_to_end_ratio', 'rb') as f:\n",
    "        user_cur_hour_start_to_end_ratio = pickle.load(f)\n",
    "    with open('./data/temp/feature_table/user_cur_hour_start_to_end_cur_hour_ratio', 'rb') as f:\n",
    "        user_cur_hour_start_to_end_cur_hour_ratio = pickle.load(f)\n",
    "        \n",
    "        \n",
    "    with open('./data/temp/feature_table/user_cur_hour_start_geofly_to_end_ratio', 'rb') as f:\n",
    "        user_cur_hour_start_geofly_to_end_ratio = pickle.load(f)\n",
    "    with open('./data/temp/feature_table/user_cur_hour_start_geofly_to_end_cur_hour_ratio', 'rb') as f:\n",
    "        user_cur_hour_start_geofly_to_end_cur_hour_ratio = pickle.load(f)\n",
    "        \n",
    "        \n",
    "        \n",
    "    #with open('./data/temp/feature_table/user_cur_hour_start_to_end_geofly_ratio', 'rb') as f:\n",
    "        #user_cur_hour_start_to_end_geofly_ratio = pickle.load(f)\n",
    "    #with open('./data/temp/feature_table/user_cur_hour_start_to_end_geofly_cur_hour_ratio', 'rb') as f:\n",
    "        #user_cur_hour_start_to_end_geofly_cur_hour_ratio = pickle.load(f)\n",
    "        \n",
    "    #with open('./data/temp/feature_table/user_cur_hour_start_geofly_to_end_geofly_ratio', 'rb') as f:\n",
    "        #user_cur_hour_start_geofly_to_end_geofly_ratio = pickle.load(f)\n",
    "    #with open('./data/temp/feature_table/user_cur_hour_start_geofly_to_end_geofly_cur_hour_ratio', 'rb') as f:\n",
    "        #user_cur_hour_start_geofly_to_end_geofly_cur_hour_ratio = pickle.load(f)\n",
    "        \n",
    "        \n",
    "    with open(outPath, 'w', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            \n",
    "            i = 0\n",
    "            csv_reader = csv.reader(open(readPath, encoding='utf-8'))\n",
    "            for row in csv_reader:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "                                \n",
    "                    row.append('cur_hour_user_start_to_end_user_ratio')\n",
    "                    row.append('cur_hour_user_start_to_end_user_cur_hour_ratio')\n",
    "                    row.append('cur_hour_user_start_geofly_to_end_user_ratio')\n",
    "                    row.append('cur_hour_user_start_geofly_to_end_user_cur_hour_ratio')\n",
    "                    \n",
    "                    #row.append('cur_hour_user_start_to_end_geofly_user_ratio')\n",
    "                    #row.append('cur_hour_user_start_to_end_geofly_user_cur_hour_ratio')\n",
    "                    #row.append('cur_hour_user_start_geofly_to_end_geofly_user_ratio')\n",
    "                    #row.append('cur_hour_user_start_geofly_to_end_geofly_user_cur_hour_ratio')\n",
    "                    \n",
    "                    row.append('cur_hour_user_end_to_start_user_ratio')\n",
    "                    row.append('cur_hour_user_end_to_start_user_cur_hour_ratio')\n",
    "                    row.append('cur_hour_user_end_geofly_to_start_user_ratio')\n",
    "                    row.append('cur_hour_user_end_geofly_to_start_user_cur_hour_ratio')\n",
    "                    \n",
    "                    #row.append('cur_hour_user_end_to_start_geofly_user_ratio')\n",
    "                    #row.append('cur_hour_user_end_to_start_geofly_user_cur_hour_ratio')\n",
    "                    #row.append('cur_hour_user_end_geofly_to_start_geofly_user_ratio')\n",
    "                    #row.append('cur_hour_user_end_geofly_to_start_geofly_user_cur_hour_ratio')\n",
    "                 \n",
    "                    writer.writerow(row)\n",
    "                    continue\n",
    " \n",
    "                user = row[1]\n",
    "                start = row[5]\n",
    "                end = row[6]    \n",
    "                hour = row[7]\n",
    "                     \n",
    "                temp_loc_start_to_end_ratio = user_cur_hour_start_to_end_ratio.get(user,{}).get(hour,{})\n",
    "                temp_loc_start_to_end_cur_hour_ratio = user_cur_hour_start_to_end_cur_hour_ratio.get(user,{}).get(hour,{})\n",
    "                \n",
    "                temp_loc_start_geofly_to_end_ratio = user_cur_hour_start_geofly_to_end_ratio.get(user,{}).get(hour,{})\n",
    "                temp_loc_start_geofly_to_end_cur_hour_ratio = user_cur_hour_start_geofly_to_end_cur_hour_ratio.get(user,{}).get(hour,{})\n",
    "                \n",
    "                #temp_loc_start_to_end_geofly_ratio = user_cur_hour_start_to_end_geofly_ratio.get(user,{}).get(hour,{})\n",
    "                #temp_loc_start_to_end_geofly_cur_hour_ratio = user_cur_hour_start_to_end_geofly_cur_hour_ratio.get(user,{}).get(hour,{})\n",
    "                \n",
    "                #temp_loc_start_geofly_to_end_geofly_ratio = user_cur_hour_start_geofly_to_end_geofly_ratio.get(user,{}).get(hour,{})\n",
    "                #temp_loc_start_geofly_to_end_geofly_cur_hour_ratio = user_cur_hour_start_geofly_to_end_geofly_cur_hour_ratio.get(user,{}).get(hour,{})\n",
    "                \n",
    "                \n",
    "                # 当前小时该用户从该起点到该终点次数／用户出发次数\n",
    "                row.append(temp_loc_start_to_end_ratio.get(start,{}).get(end,0))\n",
    "                # 当前小时该用户从该起点到该终点次数／用户该小时出发次数\n",
    "                row.append(temp_loc_start_to_end_cur_hour_ratio.get(start,{}).get(end,0))\n",
    "                # 当前小时该用户从该起点（geofly）到该终点次数／用户出发次数\n",
    "                row.append(temp_loc_start_geofly_to_end_ratio.get(start,{}).get(end,0))\n",
    "                # 当前小时该用户从该起点（geofly）到该终点次数／用户该小时出发次数\n",
    "                row.append(temp_loc_start_geofly_to_end_cur_hour_ratio.get(start,{}).get(end,0))\n",
    "                \n",
    "                # 当前小时该用户从该起点到该终点（geofly）次数／用户出发次数\n",
    "                #row.append(temp_loc_start_to_end_geofly_ratio.get(start,{}).get(end,0))\n",
    "                # 当前小时该用户从该起点到该终点（geofly）次数／用户该小时出发次数\n",
    "                #row.append(temp_loc_start_to_end_geofly_cur_hour_ratio.get(start,{}).get(end,0))\n",
    "                # 当前小时该用户从该起点（geofly）到该终点（geofly）次数／用户出发次数\n",
    "                #row.append(temp_loc_start_geofly_to_end_geofly_ratio.get(start,{}).get(end,0))\n",
    "                # 当前小时该用户从该起点（geofly）到该终点（geofly）次数／用户该小时出发次数\n",
    "                #row.append(temp_loc_start_geofly_to_end_geofly_cur_hour_ratio.get(start,{}).get(end,0))\n",
    "                \n",
    "                \n",
    "                # 当前小时该用户从该终点到该起点次数／用户出发次数\n",
    "                row.append(temp_loc_start_to_end_ratio.get(end,{}).get(start,0))\n",
    "                # 当前小时该用户从该终点到该起点次数／用户该小时出发次数\n",
    "                row.append(temp_loc_start_to_end_cur_hour_ratio.get(end,{}).get(start,0))\n",
    "                # 当前小时该用户从该终点（geofly）到该起点次数／用户出发次数\n",
    "                row.append(temp_loc_start_geofly_to_end_ratio.get(end,{}).get(start,0))\n",
    "                # 当前小时该用户从该终点（geofly）到该起点次数／用户该小时出发次数\n",
    "                row.append(temp_loc_start_geofly_to_end_cur_hour_ratio.get(end,{}).get(start,0))\n",
    "                \n",
    "                # 当前小时该用户从该终点到该起点（geofly）次数／用户出发次数\n",
    "                #row.append(temp_loc_start_to_end_geofly_ratio.get(end,{}).get(start,0))\n",
    "                # 当前小时该用户从该终点到该起点（geofly）次数／用户该小时出发次数\n",
    "                #row.append(temp_loc_start_to_end_geofly_cur_hour_ratio.get(end,{}).get(start,0))\n",
    "                # 当前小时该用户从该起点（geofly）到该终点（geofly）次数／用户出发次数\n",
    "                #row.append(temp_loc_start_geofly_to_end_geofly_ratio.get(end,{}).get(start,0))\n",
    "                # 当前小时该用户从该起点（geofly）到该终点（geofly）次数／用户该小时出发次数\n",
    "                #row.append(temp_loc_start_geofly_to_end_geofly_cur_hour_ratio.get(end,{}).get(start,0))\n",
    "                \n",
    "                \n",
    "                # 写出\n",
    "                writer.writerow(row)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_part9A(readPath='./data/train_hard_p8.csv',outPath='./data/train_hard_p9A.csv')\n",
    "insert_part9A(readPath='./data/test_hard_p8.csv',outPath='./data/test_hard_p9A.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_part9B(readPath,outPath):\n",
    "    \n",
    "    print('-------------------------------insert_part9B-------------------------------')\n",
    "    \n",
    "        \n",
    "    with open('./data/temp/feature_table/user_cur_hour_start_to_end_geofly_ratio', 'rb') as f:\n",
    "        user_cur_hour_start_to_end_geofly_ratio = pickle.load(f)\n",
    "    with open('./data/temp/feature_table/user_cur_hour_start_to_end_geofly_cur_hour_ratio', 'rb') as f:\n",
    "        user_cur_hour_start_to_end_geofly_cur_hour_ratio = pickle.load(f)\n",
    "        \n",
    "    #with open('./data/temp/feature_table/user_cur_hour_start_geofly_to_end_geofly_ratio', 'rb') as f:\n",
    "        #user_cur_hour_start_geofly_to_end_geofly_ratio = pickle.load(f)\n",
    "    #with open('./data/temp/feature_table/user_cur_hour_start_geofly_to_end_geofly_cur_hour_ratio', 'rb') as f:\n",
    "        #user_cur_hour_start_geofly_to_end_geofly_cur_hour_ratio = pickle.load(f)\n",
    "        \n",
    "        \n",
    "    with open(outPath, 'w', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            \n",
    "            i = 0\n",
    "            csv_reader = csv.reader(open(readPath, encoding='utf-8'))\n",
    "            for row in csv_reader:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "                                \n",
    "                    row.append('cur_hour_user_start_to_end_geofly_user_ratio')\n",
    "                    row.append('cur_hour_user_start_to_end_geofly_user_cur_hour_ratio')\n",
    "                    #row.append('cur_hour_user_start_geofly_to_end_geofly_user_ratio')\n",
    "                    #row.append('cur_hour_user_start_geofly_to_end_geofly_user_cur_hour_ratio')\n",
    "                    \n",
    "                    row.append('cur_hour_user_end_to_start_geofly_user_ratio')\n",
    "                    row.append('cur_hour_user_end_to_start_geofly_user_cur_hour_ratio')\n",
    "                    #row.append('cur_hour_user_end_geofly_to_start_geofly_user_ratio')\n",
    "                    #row.append('cur_hour_user_end_geofly_to_start_geofly_user_cur_hour_ratio')\n",
    "                 \n",
    "                    writer.writerow(row)\n",
    "                    continue\n",
    " \n",
    "                user = row[1]\n",
    "                start = row[5]\n",
    "                end = row[6]    \n",
    "                hour = row[7]\n",
    "                     \n",
    "                temp_loc_start_to_end_geofly_ratio = user_cur_hour_start_to_end_geofly_ratio.get(user,{}).get(hour,{})\n",
    "                temp_loc_start_to_end_geofly_cur_hour_ratio = user_cur_hour_start_to_end_geofly_cur_hour_ratio.get(user,{}).get(hour,{})\n",
    "                \n",
    "                #temp_loc_start_geofly_to_end_geofly_ratio = user_cur_hour_start_geofly_to_end_geofly_ratio.get(user,{}).get(hour,{})\n",
    "                #temp_loc_start_geofly_to_end_geofly_cur_hour_ratio = user_cur_hour_start_geofly_to_end_geofly_cur_hour_ratio.get(user,{}).get(hour,{})\n",
    "                \n",
    "                \n",
    "                # 当前小时该用户从该起点到该终点（geofly）次数／用户出发次数\n",
    "                row.append(temp_loc_start_to_end_geofly_ratio.get(start,{}).get(end,0))\n",
    "                # 当前小时该用户从该起点到该终点（geofly）次数／用户该小时出发次数\n",
    "                row.append(temp_loc_start_to_end_geofly_cur_hour_ratio.get(start,{}).get(end,0))\n",
    "                # 当前小时该用户从该起点（geofly）到该终点（geofly）次数／用户出发次数\n",
    "                #row.append(temp_loc_start_geofly_to_end_geofly_ratio.get(start,{}).get(end,0))\n",
    "                # 当前小时该用户从该起点（geofly）到该终点（geofly）次数／用户该小时出发次数\n",
    "                #row.append(temp_loc_start_geofly_to_end_geofly_cur_hour_ratio.get(start,{}).get(end,0))\n",
    "                \n",
    "                \n",
    "                # 当前小时该用户从该终点到该起点（geofly）次数／用户出发次数\n",
    "                row.append(temp_loc_start_to_end_geofly_ratio.get(end,{}).get(start,0))\n",
    "                # 当前小时该用户从该终点到该起点（geofly）次数／用户该小时出发次数\n",
    "                row.append(temp_loc_start_to_end_geofly_cur_hour_ratio.get(end,{}).get(start,0))\n",
    "                # 当前小时该用户从该起点（geofly）到该终点（geofly）次数／用户出发次数\n",
    "                #row.append(temp_loc_start_geofly_to_end_geofly_ratio.get(end,{}).get(start,0))\n",
    "                # 当前小时该用户从该起点（geofly）到该终点（geofly）次数／用户该小时出发次数\n",
    "                #row.append(temp_loc_start_geofly_to_end_geofly_cur_hour_ratio.get(end,{}).get(start,0))\n",
    "                \n",
    "                \n",
    "                # 写出\n",
    "                writer.writerow(row)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_part9B(readPath='./data/train_hard_p9A.csv',outPath='./data/train_hard_p9B.csv')\n",
    "insert_part9B(readPath='./data/test_hard_p9A.csv',outPath='./data/test_hard_p9B.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_part9C(readPath,outPath):\n",
    "    \n",
    "    print('-------------------------------insert_part9C-------------------------------')\n",
    "    \n",
    "    def read_large_pkl(file_path):\n",
    "        n_bytes = 2**31\n",
    "        max_bytes = 2**31 - 1\n",
    "\n",
    "        bytes_in = bytearray(0)\n",
    "        input_size = os.path.getsize(file_path)\n",
    "\n",
    "        with open(file_path, 'rb') as f_in:\n",
    "            for _ in range(0, input_size, max_bytes):\n",
    "                bytes_in += f_in.read(max_bytes)\n",
    "        return pickle.loads(bytes_in)\n",
    "\n",
    "    \n",
    "    user_cur_hour_start_geofly_to_end_geofly_ratio = \\\n",
    "            read_large_pkl('./data/temp/feature_table/user_cur_hour_start_geofly_to_end_geofly_ratio')    \n",
    "    #user_cur_hour_start_geofly_to_end_geofly_cur_hour_ratio = \\\n",
    "            #read_large_pkl('./data/temp/feature_table/user_cur_hour_start_geofly_to_end_geofly_cur_hour_ratio')\n",
    "    \n",
    "        \n",
    "        \n",
    "    with open(outPath, 'w', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            \n",
    "            i = 0\n",
    "            csv_reader = csv.reader(open(readPath, encoding='utf-8'))\n",
    "            for row in csv_reader:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "                                \n",
    "                    row.append('cur_hour_user_start_geofly_to_end_geofly_user_ratio')\n",
    "                    #row.append('cur_hour_user_start_geofly_to_end_geofly_user_cur_hour_ratio')\n",
    "                    \n",
    "                    row.append('cur_hour_user_end_geofly_to_start_geofly_user_ratio')\n",
    "                    #row.append('cur_hour_user_end_geofly_to_start_geofly_user_cur_hour_ratio')\n",
    "                 \n",
    "                    writer.writerow(row)\n",
    "                    continue\n",
    " \n",
    "                user = row[1]\n",
    "                start = row[5]\n",
    "                end = row[6]    \n",
    "                hour = row[7]\n",
    "                     \n",
    "                temp_loc_start_geofly_to_end_geofly_ratio = user_cur_hour_start_geofly_to_end_geofly_ratio.get(user,{}).get(hour,{})\n",
    "                #temp_loc_start_geofly_to_end_geofly_cur_hour_ratio = user_cur_hour_start_geofly_to_end_geofly_cur_hour_ratio.get(user,{}).get(hour,{})\n",
    "                \n",
    "                \n",
    "                # 当前小时该用户从该起点（geofly）到该终点（geofly）次数／用户出发次数\n",
    "                row.append(temp_loc_start_geofly_to_end_geofly_ratio.get(start,{}).get(end,0))\n",
    "                # 当前小时该用户从该起点（geofly）到该终点（geofly）次数／用户该小时出发次数\n",
    "                #row.append(temp_loc_start_geofly_to_end_geofly_cur_hour_ratio.get(start,{}).get(end,0))\n",
    "                \n",
    "                \n",
    "                # 当前小时该用户从该起点（geofly）到该终点（geofly）次数／用户出发次数\n",
    "                row.append(temp_loc_start_geofly_to_end_geofly_ratio.get(end,{}).get(start,0))\n",
    "                # 当前小时该用户从该起点（geofly）到该终点（geofly）次数／用户该小时出发次数\n",
    "                #row.append(temp_loc_start_geofly_to_end_geofly_cur_hour_ratio.get(end,{}).get(start,0))\n",
    "                \n",
    "                \n",
    "                # 写出\n",
    "                writer.writerow(row)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_part9C(readPath='./data/train_hard_p9B.csv',outPath='./data/train_hard_p9C.csv')\n",
    "insert_part9C(readPath='./data/test_hard_p9B.csv',outPath='./data/test_hard_p9C.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_part9D(readPath,outPath):\n",
    "    \n",
    "    print('-------------------------------insert_part9D-------------------------------')\n",
    "    \n",
    "    def read_large_pkl(file_path):\n",
    "        n_bytes = 2**31\n",
    "        max_bytes = 2**31 - 1\n",
    "\n",
    "        bytes_in = bytearray(0)\n",
    "        input_size = os.path.getsize(file_path)\n",
    "\n",
    "        with open(file_path, 'rb') as f_in:\n",
    "            for _ in range(0, input_size, max_bytes):\n",
    "                bytes_in += f_in.read(max_bytes)\n",
    "        return pickle.loads(bytes_in)\n",
    "\n",
    "    \n",
    "    user_cur_hour_start_geofly_to_end_geofly_cur_hour_ratio = \\\n",
    "            read_large_pkl('./data/temp/feature_table/user_cur_hour_start_geofly_to_end_geofly_cur_hour_ratio')\n",
    "    \n",
    "        \n",
    "        \n",
    "    with open(outPath, 'w', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            \n",
    "            i = 0\n",
    "            csv_reader = csv.reader(open(readPath, encoding='utf-8'))\n",
    "            for row in csv_reader:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "                                \n",
    "                    row.append('cur_hour_user_start_geofly_to_end_geofly_user_cur_hour_ratio')\n",
    "                    \n",
    "                    row.append('cur_hour_user_end_geofly_to_start_geofly_user_cur_hour_ratio')\n",
    "                 \n",
    "                    writer.writerow(row)\n",
    "                    continue\n",
    " \n",
    "                user = row[1]\n",
    "                start = row[5]\n",
    "                end = row[6]    \n",
    "                hour = row[7]\n",
    "                     \n",
    "                temp_loc_start_geofly_to_end_geofly_cur_hour_ratio = user_cur_hour_start_geofly_to_end_geofly_cur_hour_ratio.get(user,{}).get(hour,{})\n",
    "                \n",
    "                \n",
    "                # 当前小时该用户从该起点（geofly）到该终点（geofly）次数／用户该小时出发次数\n",
    "                row.append(temp_loc_start_geofly_to_end_geofly_cur_hour_ratio.get(start,{}).get(end,0))\n",
    "                \n",
    "                \n",
    "                # 当前小时该用户从该起点（geofly）到该终点（geofly）次数／用户该小时出发次数\n",
    "                row.append(temp_loc_start_geofly_to_end_geofly_cur_hour_ratio.get(end,{}).get(start,0))\n",
    "                \n",
    "                \n",
    "                # 写出\n",
    "                writer.writerow(row)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_part9D(readPath='./data/train_hard_p9C.csv',outPath='./data/train_hard_p9D.csv')\n",
    "insert_part9D(readPath='./data/test_hard_p9C.csv',outPath='./data/test_hard_p9D.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_part10(readPath,outPath):\n",
    "    \n",
    "    print('-------------------------------insert_part10-------------------------------')\n",
    "    \n",
    "    with open('./data/temp/feature_table/num_user_cur_hour_to_ratio', 'rb') as f:\n",
    "        num_user_cur_hour_to_ratio = pickle.load(f)\n",
    "    with open('./data/temp/feature_table/num_user_cur_hour_to_geofly_ratio', 'rb') as f:\n",
    "        num_user_cur_hour_to_geofly_ratio = pickle.load(f)\n",
    "    with open('./data/temp/feature_table/num_user_cur_hour_from_ratio', 'rb') as f:\n",
    "        num_user_cur_hour_from_ratio = pickle.load(f)\n",
    "    with open('./data/temp/feature_table/num_user_cur_hour_from_geofly_ratio', 'rb') as f:\n",
    "        num_user_cur_hour_from_geofly_ratio = pickle.load(f)\n",
    "        \n",
    "        \n",
    "    with open(outPath, 'w', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            \n",
    "            i = 0\n",
    "            csv_reader = csv.reader(open(readPath, encoding='utf-8'))\n",
    "            for row in csv_reader:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "      \n",
    "                    row.append('num_user_cur_hour_to_end_ratio')\n",
    "                    row.append('num_user_cur_hour_to_end_geofly_ratio')\n",
    "                    row.append('num_user_cur_hour_from_end_ratio')\n",
    "                    row.append('num_user_cur_hour_from_end_geofly_ratio')\n",
    "                    \n",
    "                    row.append('num_user_cur_hour_to_start_ratio')\n",
    "                    row.append('num_user_cur_hour_to_start_geofly_ratio')\n",
    "                    row.append('num_user_cur_hour_from_start_ratio')\n",
    "                    row.append('num_user_cur_hour_from_start_geofly_ratio')\n",
    "                 \n",
    "                    writer.writerow(row)\n",
    "                    continue\n",
    " \n",
    "                user = row[1]\n",
    "                start = row[5]\n",
    "                end = row[6]    \n",
    "                hour = row[7]\n",
    "                     \n",
    "                temp_num_user_cur_hour_to_ratio = num_user_cur_hour_to_ratio.get(hour,{})\n",
    "                temp_num_user_cur_hour_to_geofly_ratio = num_user_cur_hour_to_geofly_ratio.get(hour,{})\n",
    "                temp_num_user_cur_hour_from_ratio = num_user_cur_hour_from_ratio.get(hour,{})\n",
    "                temp_num_user_cur_hour_from_geofly_ratio = num_user_cur_hour_from_geofly_ratio.get(hour,{})\n",
    "                \n",
    "                # 终点\n",
    "                row.append(temp_num_user_cur_hour_to_ratio.get(end,0))\n",
    "                row.append(temp_num_user_cur_hour_to_geofly_ratio.get(end,0))\n",
    "                row.append(temp_num_user_cur_hour_from_ratio.get(end,0))\n",
    "                row.append(temp_num_user_cur_hour_from_geofly_ratio.get(end,0))\n",
    "\n",
    "                # 起点\n",
    "                row.append(temp_num_user_cur_hour_to_ratio.get(start,0))\n",
    "                row.append(temp_num_user_cur_hour_to_geofly_ratio.get(start,0))\n",
    "                row.append(temp_num_user_cur_hour_from_ratio.get(start,0))\n",
    "                row.append(temp_num_user_cur_hour_from_geofly_ratio.get(start,0))\n",
    "                # 写出\n",
    "                writer.writerow(row)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_part10(readPath='./data/train_hard_p9D.csv',outPath='./data/train_hard_p10.csv')\n",
    "insert_part10(readPath='./data/test_hard_p9D.csv',outPath='./data/test_hard_p10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_part11(readPath,outPath):\n",
    "    \n",
    "    print('-------------------------------insert_part11-------------------------------')\n",
    "    \n",
    "    with open('./data/temp/feature_table/num_user_cur_hour_to_cur_hour_ratio', 'rb') as f:\n",
    "        num_user_cur_hour_to_cur_hour_ratio = pickle.load(f)\n",
    "    with open('./data/temp/feature_table/num_user_cur_hour_to_geofly_cur_hour_ratio', 'rb') as f:\n",
    "        num_user_cur_hour_to_geofly_cur_hour_ratio = pickle.load(f)\n",
    "    with open('./data/temp/feature_table/num_user_cur_hour_from_cur_hour_ratio', 'rb') as f:\n",
    "        num_user_cur_hour_from_cur_hour_ratio = pickle.load(f)\n",
    "    with open('./data/temp/feature_table/num_user_cur_hour_from_geofly_cur_hour_ratio', 'rb') as f:\n",
    "        num_user_cur_hour_from_geofly_cur_hour_ratio = pickle.load(f)\n",
    "        \n",
    "        \n",
    "    with open(outPath, 'w', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            \n",
    "            i = 0\n",
    "            csv_reader = csv.reader(open(readPath, encoding='utf-8'))\n",
    "            for row in csv_reader:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "                    \n",
    "                    row.append('num_user_cur_hour_to_end_cur_hour_ratio')\n",
    "                    row.append('num_user_cur_hour_to_end_geofly_cur_hour_ratio')\n",
    "                    row.append('num_user_cur_hour_from_end_cur_hour_ratio')\n",
    "                    row.append('num_user_cur_hour_from_end_geofly_cur_hour_ratio')\n",
    "                    \n",
    "                    row.append('num_user_cur_hour_to_start_cur_hour_ratio')\n",
    "                    row.append('num_user_cur_hour_to_start_geofly_cur_hour_ratio')\n",
    "                    row.append('num_user_cur_hour_from_start_cur_hour_ratio')\n",
    "                    row.append('num_user_cur_hour_from_start_geofly_cur_hour_ratio')\n",
    "                 \n",
    "                    writer.writerow(row)\n",
    "                    continue\n",
    " \n",
    "                user = row[1]\n",
    "                start = row[5]\n",
    "                end = row[6]    \n",
    "                hour = row[7]\n",
    "                     \n",
    "                temp_num_user_cur_hour_to_ratio = num_user_cur_hour_to_cur_hour_ratio.get(hour,{})\n",
    "                temp_num_user_cur_hour_to_geofly_ratio = num_user_cur_hour_to_geofly_cur_hour_ratio.get(hour,{})\n",
    "                temp_num_user_cur_hour_from_ratio = num_user_cur_hour_from_cur_hour_ratio.get(hour,{})\n",
    "                temp_num_user_cur_hour_from_geofly_ratio = num_user_cur_hour_from_geofly_cur_hour_ratio.get(hour,{})\n",
    "                \n",
    "                # 终点\n",
    "                row.append(temp_num_user_cur_hour_to_ratio.get(end,0))\n",
    "                row.append(temp_num_user_cur_hour_to_geofly_ratio.get(end,0))\n",
    "                row.append(temp_num_user_cur_hour_from_ratio.get(end,0))\n",
    "                row.append(temp_num_user_cur_hour_from_geofly_ratio.get(end,0))\n",
    "\n",
    "                # 起点\n",
    "                row.append(temp_num_user_cur_hour_to_ratio.get(start,0))\n",
    "                row.append(temp_num_user_cur_hour_to_geofly_ratio.get(start,0))\n",
    "                row.append(temp_num_user_cur_hour_from_ratio.get(start,0))\n",
    "                row.append(temp_num_user_cur_hour_from_geofly_ratio.get(start,0))\n",
    "                # 写出\n",
    "                writer.writerow(row)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_part11(readPath='./data/train_hard_p10.csv',outPath='./data/train_hard_p11.csv')\n",
    "insert_part11(readPath='./data/test_hard_p10.csv',outPath='./data/test_hard_p11.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不完全缓存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Incomplete_caching_part1(readPath,outPath):\n",
    "    \n",
    "    print('-------------------------------Incomplete_caching_part1-------------------------------')\n",
    "    \n",
    "    with open('./data/temp/Incomplete_caching/man_dis_dic', 'rb') as f:\n",
    "        man_dis_dic = pickle.load(f)\n",
    "    with open('./data/temp/Incomplete_caching/direction_dic', 'rb') as f:\n",
    "        direction_dic = pickle.load(f)\n",
    "    with open('./data/temp/Incomplete_caching/lat_diff_dic', 'rb') as f:\n",
    "        lat_diff_dic = pickle.load(f)\n",
    "    with open('./data/temp/Incomplete_caching/long_diff_dic', 'rb') as f:\n",
    "        long_diff_dic = pickle.load(f)\n",
    "        \n",
    "             \n",
    "    with open(outPath, 'w', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            \n",
    "            i = 0\n",
    "            csv_reader = csv.reader(open(readPath, encoding='utf-8'))\n",
    "            for row in csv_reader:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "           \n",
    "                    row.append('start_to_end_man_dis')\n",
    "                    row.append('lat_different')\n",
    "                    row.append('long_different')\n",
    "                    row.append('direction')\n",
    "                    \n",
    "                    writer.writerow(row)\n",
    "                    continue\n",
    " \n",
    "                user = row[1]\n",
    "                start = row[5]\n",
    "                end = row[6]    \n",
    "                hour = row[7]\n",
    "                     \n",
    "                temp = man_dis_dic.get(start,{}).get(end,-1)\n",
    "                if temp == -1:\n",
    "                    row.append(function.getManhattan(start,end))\n",
    "                else:\n",
    "                    row.append(temp)\n",
    "                    \n",
    "                temp = lat_diff_dic.get(start,{}).get(end,-1)\n",
    "                if temp == -1:\n",
    "                    \n",
    "                    lat1 = function.decode_exactly(start)[0]\n",
    "                    lat2 = function.decode_exactly(end)[0]\n",
    "                    row.append(abs(lat1 - lat2))\n",
    "                    \n",
    "                else:\n",
    "                    row.append(temp)\n",
    "                    \n",
    "                temp = long_diff_dic.get(start,{}).get(end,-1)\n",
    "                if temp == -1:\n",
    "                    \n",
    "                    long1 = function.decode_exactly(start)[1]\n",
    "                    long2 = function.decode_exactly(end)[1]\n",
    "                    row.append(abs(long1 - long2))\n",
    "                    \n",
    "                else:\n",
    "                    row.append(temp)\n",
    "                    \n",
    "                \n",
    "                temp = direction_dic.get(start,{}).get(end,-1)\n",
    "                if temp == -1:\n",
    "                    \n",
    "                    direction = function.getDegree(start,end)\n",
    "            \n",
    "                    if direction < 22.5 or 337.5 <= direction:\n",
    "                        direction = 0\n",
    "                    elif 22.5 <= direction and direction < 67.5:\n",
    "                        direction = 1\n",
    "                    elif 67.5 <= direction and direction < 112.5:\n",
    "                        direction = 2\n",
    "                    elif 112.5 <= direction and direction < 157.5:\n",
    "                        direction = 3\n",
    "                    elif 157.5 <= direction and direction < 202.5:\n",
    "                        direction = 4\n",
    "                    elif 202.5 <= direction and direction < 247.5:\n",
    "                        direction = 5\n",
    "                    elif 247.5 <= direction and direction < 292.5:\n",
    "                        direction = 6\n",
    "                    elif 292.5 <= direction and direction < 337.5:\n",
    "                        direction = 7\n",
    "                    row.append(direction)\n",
    "                    \n",
    "                else:\n",
    "                    row.append(temp)\n",
    "                \n",
    "                \n",
    "                # 写出\n",
    "                writer.writerow(row)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Incomplete_caching_part1(readPath='./data/train_hard_p11.csv',outPath='./data/train_hard_p11_p1.csv')\n",
    "Incomplete_caching_part1(readPath='./data/test_hard_p11.csv',outPath='./data/test_hard_p11_p1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Incomplete_caching_part2(readPath,outPath):\n",
    "    \n",
    "    def rad_s(tude):\n",
    "        return (math.pi/180.0)*tude\n",
    "    \n",
    "    def getManhattan_s(loc,hotEndLocation):\n",
    "    \n",
    "        R = 6378137\n",
    "        #当纬度差是0\n",
    "        latitude1 = loc[0]\n",
    "        longitude1 = loc[1]\n",
    "\n",
    "        latitude2 = loc[0]\n",
    "        longitude2 = function.decode_exactly(hotEndLocation)[1]\n",
    "\n",
    "        radLat1 = rad_s(latitude1)\n",
    "        radLat2 = rad_s(latitude2)\n",
    "        a = radLat1-radLat2\n",
    "        b = rad_s(longitude1)-rad_s(longitude2)\n",
    "        d1 = R*2*math.asin(math.sqrt(math.pow(math.sin(a/2),2)+math.cos(radLat1)*math.cos(radLat2)*math.pow(math.sin(b/2),2)))\n",
    "\n",
    "        #当经度差是0\n",
    "        latitude1 = loc[0]\n",
    "        longitude1 = loc[1]\n",
    "\n",
    "        latitude2 = function.decode_exactly(hotEndLocation)[0]\n",
    "        longitude2 = loc[1]\n",
    "\n",
    "        radLat1 = rad_s(latitude1)\n",
    "        radLat2 = rad_s(latitude2)\n",
    "        a = radLat1-radLat2\n",
    "        b = rad_s(longitude1)-rad_s(longitude2)\n",
    "        d2 = R*2*math.asin(math.sqrt(math.pow(math.sin(a/2),2)+math.cos(radLat1)*math.cos(radLat2)*math.pow(math.sin(b/2),2)))\n",
    "\n",
    "        #曼哈顿距离\n",
    "        return round(d1+d2)\n",
    "    \n",
    "    print('-------------------------------Incomplete_caching_part2-------------------------------')\n",
    "    \n",
    "    with open('./data/temp/Incomplete_caching/user_center', 'rb') as f:\n",
    "        user_center = pickle.load(f)\n",
    "    with open('./data/temp/Incomplete_caching/bike_center', 'rb') as f:\n",
    "        bike_center = pickle.load(f)\n",
    "        \n",
    "    with open(outPath, 'w', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            \n",
    "            i = 0\n",
    "            csv_reader = csv.reader(open(readPath, encoding='utf-8'))\n",
    "            for row in csv_reader:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "           \n",
    "                    row.append('end_user_active_center_dis')\n",
    "                    row.append('start_user_active_center_dis')\n",
    "                    row.append('end_bike_active_center_dis')\n",
    "                    row.append('start_bike_active_center_dis')\n",
    "                    \n",
    "                    writer.writerow(row)\n",
    "                    continue\n",
    " \n",
    "                user = row[1]\n",
    "                bike = row[2]\n",
    "                start = row[5]\n",
    "                end = row[6]    \n",
    "                \n",
    "                # end_user_active_center_dis\n",
    "                temp = user_center.get(user,-1)\n",
    "                if temp == -1:\n",
    "                    row.append('')\n",
    "                else:\n",
    "                    min_dis = 99999999\n",
    "                    for x in temp[0]:\n",
    "                        \n",
    "                        temp_dis = getManhattan_s(x,end)\n",
    "                        if temp_dis < min_dis:\n",
    "                            min_dis = temp_dis\n",
    "\n",
    "                    row.append(min_dis)\n",
    "                    \n",
    "                # start_user_active_center_dis\n",
    "                temp = user_center.get(user,-1)\n",
    "                if temp == -1:\n",
    "                    row.append('')\n",
    "                else:\n",
    "                    min_dis = 99999999\n",
    "                    for x in temp[0]:\n",
    "                        \n",
    "                        temp_dis = getManhattan_s(x,start)\n",
    "                        if temp_dis < min_dis:\n",
    "                            min_dis = temp_dis\n",
    "                            \n",
    "                    row.append(min_dis)\n",
    "                    \n",
    "                # end_bike_active_center_dis\n",
    "                temp = user_center.get(bike,-1)\n",
    "                if temp == -1:\n",
    "                    row.append('')\n",
    "                else:\n",
    "                    min_dis = 99999999\n",
    "                    for x in temp[0]:\n",
    "                        \n",
    "                        temp_dis = getManhattan_s(x,end)\n",
    "                        if temp_dis < min_dis:\n",
    "                            min_dis = temp_dis\n",
    "                            \n",
    "                    row.append(min_dis)\n",
    "                    \n",
    "                # start_bike_active_center_dis\n",
    "                temp = user_center.get(bike,-1)\n",
    "                if temp == -1:\n",
    "                    row.append('')\n",
    "                else:\n",
    "                    min_dis = 99999999\n",
    "                    for x in temp[0]:\n",
    "                        \n",
    "                        temp_dis = getManhattan_s(x,start)\n",
    "                        if temp_dis < min_dis:\n",
    "                            min_dis = temp_dis\n",
    "                            \n",
    "                    row.append(min_dis)\n",
    "                    \n",
    "                # 写出\n",
    "                writer.writerow(row)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Incomplete_caching_part2(readPath='./data/train_hard_p11_p1.csv',outPath='./data/train_hard_p11_p2.csv')\n",
    "Incomplete_caching_part2(readPath='./data/test_hard_p11_p1.csv',outPath='./data/test_hard_p11_p2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Incomplete_caching_part3(readPath,outPath):\n",
    "    \n",
    "    print('-------------------------------Incomplete_caching_part3-------------------------------')\n",
    "    \n",
    "    with open('./data/temp/Incomplete_caching/man_dis_dic', 'rb') as f:\n",
    "        man_dis_dic = pickle.load(f)\n",
    "    \n",
    "    user_dis_info = {}\n",
    "    i = 0\n",
    "    csv_reader = csv.reader(open('./data/temp/user_dis_info.csv', encoding='utf-8'))\n",
    "    for row in csv_reader:\n",
    "        i += 1\n",
    "        if i == 1:\n",
    "            continue\n",
    "        user_dis_info[row[0]] = eval(row[1])\n",
    "        \n",
    "        \n",
    "    with open(outPath, 'w', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            \n",
    "            i = 0\n",
    "            csv_reader = csv.reader(open(readPath, encoding='utf-8'))\n",
    "            for row in csv_reader:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "                    \n",
    "                    row.append('diff_cur_dis_user_max_dis')\n",
    "                    row.append('diff_cur_dis_user_min_dis')\n",
    "                    row.append('diff_cur_dis_user_avg_dis')\n",
    "                    \n",
    "                    writer.writerow(row)\n",
    "                    continue\n",
    " \n",
    "                user = row[1]\n",
    "                start = row[5]\n",
    "                end = row[6]    \n",
    "            \n",
    "                man_dis = man_dis_dic.get(start,{}).get(end,-1)\n",
    "                if man_dis == -1:\n",
    "                    man_dis = man_dis_dic.get(end,{}).get(start,-1)\n",
    "                    if man_dis == -1:\n",
    "                        man_dis = function.getManhattan(start,end)\n",
    "\n",
    "                \n",
    "                temp = user_dis_info.get(user,-1)\n",
    "                if temp == -1:\n",
    "                    \n",
    "                    row.append('')\n",
    "                    row.append('')\n",
    "                    row.append('')\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    man_dis = int(man_dis)\n",
    "                    \n",
    "                    \n",
    "                    row.append(man_dis/temp[0])\n",
    "                    row.append(man_dis/temp[1])\n",
    "                    row.append(man_dis/temp[2])\n",
    "                    \n",
    "                # 写出\n",
    "                writer.writerow(row)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Incomplete_caching_part3(readPath='./data/train_hard_p11_p2.csv',outPath='./data/train_hard_p11_p3.csv')\n",
    "Incomplete_caching_part3(readPath='./data/test_hard_p11_p2.csv',outPath='./data/test_hard_p11_p3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part4（忽略）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Incomplete_caching_part4(readPath,outPath):\n",
    "    \n",
    "    print('-------------------------------Incomplete_caching_part4-------------------------------')\n",
    "    \n",
    "    with open('./data/temp/Incomplete_caching/user_used_time', 'rb') as f:\n",
    "        user_used_time = pickle.load(f)\n",
    "    with open('./data/temp/Incomplete_caching/man_dis_dic', 'rb') as f:\n",
    "        man_dis_dic = pickle.load(f)\n",
    "         \n",
    "    with open(outPath, 'w', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            \n",
    "            i = 0\n",
    "            csv_reader = csv.reader(open(readPath, encoding='utf-8'))\n",
    "            for row in csv_reader:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "                    \n",
    "                    row.append('end_next_start_man_dis')\n",
    "                    \n",
    "                    writer.writerow(row)\n",
    "                    continue\n",
    " \n",
    "                user = row[1]\n",
    "                starttime = row[4]\n",
    "                start = row[5]\n",
    "                end = row[6]\n",
    "                \n",
    "                if int(user) in user_used_time:\n",
    "                    df = user_used_time[int(user)]\n",
    "                    \n",
    "                    if df[df.starttime>starttime].shape[0] == 0:\n",
    "                        row.append('')\n",
    "                    else:\n",
    "                        next_start = df[df.starttime>starttime].iloc[0].geohashed_start_loc\n",
    "                        \n",
    "                        man_dis = man_dis_dic.get(start,{}).get(end,-1)\n",
    "                        if man_dis == -1:\n",
    "                            man_dis = man_dis_dic.get(end,{}).get(start,-1)\n",
    "                            if man_dis == -1:\n",
    "                                man_dis = function.getManhattan(start,end)\n",
    "                        \n",
    "                else:\n",
    "                    row.append('')\n",
    "                                    \n",
    "                \n",
    "                # 写出\n",
    "                writer.writerow(row)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Incomplete_caching_part4(readPath='./data/train_hard_p11_p3.csv',outPath='./data/train_hard_p11_p4.csv')\n",
    "Incomplete_caching_part4(readPath='./data/test_hard_p11_p3.csv',outPath='./data/test_hard_p11_p4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/temp/Incomplete_caching/user_to_time', 'rb') as f:\n",
    "        user_to_time = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Incomplete_caching_part5(readPath,outPath):\n",
    "    \n",
    "    def get_min_hour_diff(x,hour_set):\n",
    "        \n",
    "        min_diff = 24\n",
    "        \n",
    "        for h in hour_set:\n",
    "            if abs(x - h) < 24:\n",
    "                min_diff = abs(x - h)\n",
    "        return min_diff\n",
    "  \n",
    "    print('-------------------------------Incomplete_caching_part5-------------------------------')\n",
    "    \n",
    "    with open('./data/temp/Incomplete_caching/user_to_time', 'rb') as f:\n",
    "        user_to_time = pickle.load(f)\n",
    "    with open('./data/temp/Incomplete_caching/user_to_geofly_time', 'rb') as f:\n",
    "        user_to_geofly_time = pickle.load(f)\n",
    "    with open('./data/temp/Incomplete_caching/user_from_time', 'rb') as f:\n",
    "        user_from_time = pickle.load(f)\n",
    "    with open('./data/temp/Incomplete_caching/user_from_geofly_time', 'rb') as f:\n",
    "        user_from_geofly_time = pickle.load(f)\n",
    "         \n",
    "    with open(outPath, 'w', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            \n",
    "            i = 0\n",
    "            csv_reader = csv.reader(open(readPath, encoding='utf-8'))\n",
    "            for row in csv_reader:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "                                       \n",
    "                    row.append('user_to_end_min_time_diff')\n",
    "                    row.append('user_to_end_geofly_min_time_diff')\n",
    "                    row.append('user_from_end_min_time_diff')\n",
    "                    row.append('user_from_end_geofly_min_time_diff')\n",
    "                    row.append('user_to_start_min_time_diff')\n",
    "                    row.append('user_to_start_geofly_min_time_diff')\n",
    "                    row.append('user_from_start_min_time_diff')\n",
    "                    row.append('user_from_start_geofly_min_time_diff')\n",
    "                    \n",
    "                    writer.writerow(row)\n",
    "                    continue\n",
    " \n",
    "                user = row[1]\n",
    "                starttime = row[4]\n",
    "                start = row[5]\n",
    "                end = row[6]\n",
    "                hour = int(row[7])\n",
    "                \n",
    "                user_to = user_to_time.get(user,{})\n",
    "                user_to_geofly = user_to_geofly_time.get(user,{})\n",
    "                \n",
    "                user_from = user_from_time.get(user,{})\n",
    "                user_from_geofly = user_from_geofly_time.get(user,{})\n",
    "                \n",
    "                \n",
    "                row.append(get_min_hour_diff(hour,user_to.get(end,set())))\n",
    "                row.append(get_min_hour_diff(hour,user_to_geofly.get(end,set())))\n",
    "                row.append(get_min_hour_diff(hour,user_from.get(end,set())))\n",
    "                row.append(get_min_hour_diff(hour,user_from_geofly.get(end,set())))\n",
    "                \n",
    "                \n",
    "                row.append(get_min_hour_diff(hour,user_to.get(start,set())))\n",
    "                row.append(get_min_hour_diff(hour,user_to_geofly.get(start,set())))\n",
    "                row.append(get_min_hour_diff(hour,user_from.get(start,set())))\n",
    "                row.append(get_min_hour_diff(hour,user_from_geofly.get(start,set())))\n",
    "                \n",
    "                # 写出\n",
    "                writer.writerow(row)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Incomplete_caching_part5(readPath='./data/train_hard_p11_p3.csv',outPath='./data/train_hard_p11_p5.csv')\n",
    "Incomplete_caching_part5(readPath='./data/test_hard_p11_p3.csv',outPath='./data/test_hard_p11_p5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Incomplete_caching_part6A(readPath,outPath):\n",
    "    \n",
    "    def get_min_hour_diff(x,hour_set):\n",
    "        \n",
    "        min_diff = 24\n",
    "        \n",
    "        for h in hour_set:\n",
    "            if abs(x - h) < 24:\n",
    "                min_diff = abs(x - h)\n",
    "        return min_diff\n",
    "  \n",
    "    print('-------------------------------Incomplete_caching_part5-------------------------------')\n",
    "    \n",
    "    with open('./data/temp/Incomplete_caching/user_start_to_end_time', 'rb') as f:\n",
    "        user_start_to_end_time = pickle.load(f)\n",
    "    with open('./data/temp/Incomplete_caching/user_start_to_end_geofly_time', 'rb') as f:\n",
    "        user_start_to_end_geofly_time = pickle.load(f)\n",
    "    with open('./data/temp/Incomplete_caching/user_start_geofly_to_end_time', 'rb') as f:\n",
    "        user_start_geofly_to_end_time = pickle.load(f)\n",
    "       \n",
    "    with open(outPath, 'w', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            \n",
    "            i = 0\n",
    "            csv_reader = csv.reader(open(readPath, encoding='utf-8'))\n",
    "            for row in csv_reader:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "                                                   \n",
    "                    row.append('user_start_to_end_min_time_diff')\n",
    "                    row.append('user_start_to_end_geofly_min_time_diff')\n",
    "                    row.append('user_start_geofly_to_end_min_time_diff')\n",
    "                    #row.append('user_start_geofly_to_end_geofly_min_time_diff')\n",
    "                    row.append('user_end_to_start_min_time_diff')\n",
    "                    row.append('user_end_to_start_geofly_min_time_diff')\n",
    "                    row.append('user_end_geofly_to_start_min_time_diff')\n",
    "                    #row.append('user_end_geofly_to_start_geofly_min_time_diff')\n",
    "                    \n",
    "                    writer.writerow(row)\n",
    "                    continue\n",
    " \n",
    "                user = row[1]\n",
    "                starttime = row[4]\n",
    "                start = row[5]\n",
    "                end = row[6]\n",
    "                hour = int(row[7])\n",
    "                \n",
    "                user_start_to_end = user_start_to_end_time.get(user,{})\n",
    "                user_start_to_end_geofly = user_start_to_end_geofly_time.get(user,{})\n",
    "                user_start_geofly_to_end = user_start_geofly_to_end_time.get(user,{})\n",
    "                \n",
    "                \n",
    "                row.append(get_min_hour_diff(hour,user_start_to_end.get(start,{}).get(end,set())))\n",
    "                row.append(get_min_hour_diff(hour,user_start_to_end_geofly.get(start,{}).get(end,set())))\n",
    "                row.append(get_min_hour_diff(hour,user_start_geofly_to_end.get(start,{}).get(end,set())))\n",
    "                \n",
    "                row.append(get_min_hour_diff(hour,user_start_to_end.get(end,{}).get(start,set())))\n",
    "                row.append(get_min_hour_diff(hour,user_start_to_end_geofly.get(end,{}).get(start,set())))\n",
    "                row.append(get_min_hour_diff(hour,user_start_geofly_to_end.get(end,{}).get(start,set())))\n",
    "                \n",
    "                # 写出\n",
    "                writer.writerow(row)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Incomplete_caching_part6A(readPath='./data/train_hard_p11_p5.csv',outPath='./data/train_hard_p11_p6A.csv')\n",
    "Incomplete_caching_part6A(readPath='./data/test_hard_p11_p5.csv',outPath='./data/test_hard_p11_p6A.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
